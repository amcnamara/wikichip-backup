<!DOCTYPE html><html class="client-nojs" lang="en" dir="ltr"><head><meta charset="UTF-8"/>
<script data-ezscrex='false' data-cfasync='false' data-pagespeed-no-defer>var __ez=__ez||{};__ez.stms=Date.now();__ez.evt={};__ez.script={};__ez.ck=__ez.ck||{};__ez.template={};__ez.template.isOrig=true;__ez.queue=function(){var e=0,i=0,t=[],n=!1,o=[],r=[],s=!0,a=function(e,i,n,o,r,s,a){var l=arguments.length>7&&void 0!==arguments[7]?arguments[7]:window,d=this;this.name=e,this.funcName=i,this.parameters=null===n?null:p(n)?n:[n],this.isBlock=o,this.blockedBy=r,this.deleteWhenComplete=s,this.isError=!1,this.isComplete=!1,this.isInitialized=!1,this.proceedIfError=a,this.fWindow=l,this.isTimeDelay=!1,this.process=function(){f("... func = "+e),d.isInitialized=!0,d.isComplete=!0,f("... func.apply: "+e);var i=d.funcName.split("."),n=null,o=this.fWindow||window;i.length>3||(n=3===i.length?o[i[0]][i[1]][i[2]]:2===i.length?o[i[0]][i[1]]:o[d.funcName]),null!=n&&n.apply(null,this.parameters),!0===d.deleteWhenComplete&&delete t[e],!0===d.isBlock&&(f("----- F'D: "+d.name),u())}},l=function(e,i,t,n,o,r,s){var a=arguments.length>7&&void 0!==arguments[7]?arguments[7]:window,l=this;this.name=e,this.path=i,this.async=o,this.defer=r,this.isBlock=t,this.blockedBy=n,this.isInitialized=!1,this.isError=!1,this.isComplete=!1,this.proceedIfError=s,this.fWindow=a,this.isTimeDelay=!1,this.isPath=function(e){return"/"===e[0]&&"/"!==e[1]},this.getSrc=function(e){return void 0!==window.__ezScriptHost&&this.isPath(e)&&"banger.js"!==this.name?window.__ezScriptHost+e:e},this.process=function(){l.isInitialized=!0,f("... file = "+e);var i=this.fWindow?this.fWindow.document:document,t=i.createElement("script");t.src=this.getSrc(this.path),!0===o?t.async=!0:!0===r&&(t.defer=!0),t.onerror=function(){var e={url:window.location.href,name:l.name,path:l.path,user_agent:window.navigator.userAgent};"undefined"!=typeof _ezaq&&(e.pageview_id=_ezaq.page_view_id);var i=encodeURIComponent(JSON.stringify(e)),t=new XMLHttpRequest;t.open("GET","//g.ezoic.net/ezqlog?d="+i,!0),t.send(),f("----- ERR'D: "+l.name),l.isError=!0,!0===l.isBlock&&u()},t.onreadystatechange=t.onload=function(){var e=t.readyState;f("----- F'D: "+l.name),e&&!/loaded|complete/.test(e)||(l.isComplete=!0,!0===l.isBlock&&u())},i.getElementsByTagName("head")[0].appendChild(t)}},d=function(e,i){this.name=e,this.path="",this.async=!1,this.defer=!1,this.isBlock=!1,this.blockedBy=[],this.isInitialized=!0,this.isError=!1,this.isComplete=i,this.proceedIfError=!1,this.isTimeDelay=!1,this.process=function(){}};function c(e){!0!==h(e)&&0!=s&&e.process()}function h(e){if(!0===e.isTimeDelay&&!1===n)return f(e.name+" blocked = TIME DELAY!"),!0;if(p(e.blockedBy))for(var i=0;i<e.blockedBy.length;i++){var o=e.blockedBy[i];if(!1===t.hasOwnProperty(o))return f(e.name+" blocked = "+o),!0;if(!0===e.proceedIfError&&!0===t[o].isError)return!1;if(!1===t[o].isComplete)return f(e.name+" blocked = "+o),!0}return!1}function f(e){var i=window.location.href,t=new RegExp("[?&]ezq=([^&#]*)","i").exec(i);"1"===(t?t[1]:null)&&console.debug(e)}function u(){++e>200||(f("let's go"),m(o),m(r))}function m(e){for(var i in e)if(!1!==e.hasOwnProperty(i)){var t=e[i];!0===t.isComplete||h(t)||!0===t.isInitialized||!0===t.isError?!0===t.isError?f(t.name+": error"):!0===t.isComplete?f(t.name+": complete already"):!0===t.isInitialized&&f(t.name+": initialized already"):t.process()}}function p(e){return"[object Array]"==Object.prototype.toString.call(e)}return window.addEventListener("load",(function(){setTimeout((function(){n=!0,f("TDELAY -----"),u()}),5e3)}),!1),{addFile:function(e,i,n,s,a,d,h,f,u){var m=new l(e,i,n,s,a,d,h,u);!0===f?o[e]=m:r[e]=m,t[e]=m,c(m)},addDelayFile:function(e,i){var n=new l(e,i,!1,[],!1,!1,!0);n.isTimeDelay=!0,f(e+" ...  FILE! TDELAY"),r[e]=n,t[e]=n,c(n)},addFunc:function(e,n,s,l,d,h,f,u,m,p){!0===h&&(e=e+"_"+i++);var w=new a(e,n,s,l,d,f,u,p);!0===m?o[e]=w:r[e]=w,t[e]=w,c(w)},addDelayFunc:function(e,i,n){var o=new a(e,i,n,!1,[],!0,!0);o.isTimeDelay=!0,f(e+" ...  FUNCTION! TDELAY"),r[e]=o,t[e]=o,c(o)},items:t,processAll:u,setallowLoad:function(e){s=e},markLoaded:function(e){if(e&&0!==e.length){if(e in t){var i=t[e];!0===i.isComplete?f(i.name+" "+e+": error loaded duplicate"):(i.isComplete=!0,i.isInitialized=!0)}else t[e]=new d(e,!0);f("markLoaded dummyfile: "+t[e].name)}},logWhatsBlocked:function(){for(var e in t)!1!==t.hasOwnProperty(e)&&h(t[e])}}}();__ez.evt.add=function(e,t,n){e.addEventListener?e.addEventListener(t,n,!1):e.attachEvent?e.attachEvent("on"+t,n):e["on"+t]=n()},__ez.evt.remove=function(e,t,n){e.removeEventListener?e.removeEventListener(t,n,!1):e.detachEvent?e.detachEvent("on"+t,n):delete e["on"+t]};__ez.script.add=function(e){var t=document.createElement("script");t.src=e,t.async=!0,t.type="text/javascript",document.getElementsByTagName("head")[0].appendChild(t)};__ez.dot={};__ez.queue.addFile('/detroitchicago/boise.js', '/detroitchicago/boise.js?gcb=195-3&cb=2', true, [], true, false, true, false);__ez.queue.addFile('/parsonsmaize/abilene.js', '/parsonsmaize/abilene.js?gcb=195-3&cb=30', true, [], true, false, true, false);</script>
<script data-ezscrex="false" type="text/javascript" data-cfasync="false">window._ezaq = Object.assign({}, typeof window._ezaq !== "undefined" ? window._ezaq : {}, {"ad_cache_level":1,"domain_id":86609,"ezcache_level":0,"ezcache_skip_code":0,"has_bad_image":0,"has_bad_words":0,"is_sitespeed":0,"lt_cache_level":0,"page_view_id":"3fd855eb-21fc-4432-776c-0c5fdb58fd88","response_size_orig":184083,"response_time_orig":225,"template_id":5,"url":"/wiki/x86/avx512","word_count":0,"worst_bad_word_level":0});__ez.queue.markLoaded('ezaqBaseReady');</script>
<script data-ezscrex='false' data-cfasync='false' data-pagespeed-no-defer>__ez.queue.addFile('/parsonsmaize/mulvane.js', '/parsonsmaize/mulvane.js?gcb=195-3&cb=5', true, ['/parsonsmaize/abilene.js'], true, false, true, false);__ez.queue.addFile('/parsonsmaize/olathe.js', '/parsonsmaize/olathe.js?gcb=195-3&cb=23', false, ['/parsonsmaize/abilene.js','/parsonsmaize/mulvane.js'], true, false, true, false);__ez.queue.addFile('/porpoiseant/et.js', '/porpoiseant/et.js?gcb=195-3&cb=2', false, [], true, false, true, false);!function(){var e;__ez.vep=(e=[],{Add:function(i,t){__ez.dot.isDefined(i)&&__ez.dot.isValid(t)&&e.push({type:"video",video_impression_id:i,domain_id:__ez.dot.getDID(),t_epoch:__ez.dot.getEpoch(0),data:__ez.dot.dataToStr(t)})},Fire:function(){if(void 0===document.visibilityState||"prerender"!==document.visibilityState){if(__ez.dot.isDefined(e)&&e.length>0)for(;e.length>0;){var i=5;i>e.length&&(i=e.length);var t=e.splice(0,i),o=__ez.dot.getURL("/detroitchicago/grapefruit.gif")+"?orig="+(!0===__ez.template.isOrig?1:0)+"&v="+btoa(JSON.stringify(t));__ez.dot.Fire(o)}e=[]}}})}();</script><script data-ezscrex='false' data-cfasync='false' data-pagespeed-no-defer>!function(){function e(i){return e="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},e(i)}__ez.pel=function(){var i=[];function t(t,o,d,_,n,r,a,f){if(__ez.dot.isDefined(t)&&0!=__ez.dot.isAnyDefined(t.getSlotElementId,t.ElementId)){void 0===f&&(f=!1),parseInt(__ez.dot.getTargeting(t,"ap"));var p=__ez.dot.getSlotIID(t),s=__ez.dot.getAdUnit(t,f),u=parseInt(__ez.dot.getTargeting(t,"compid")),l=0,g=0,z=function(i){if("undefined"==typeof _ezim_d)return!1;var t=__ez.dot.getAdUnitPath(i).split("/").pop();if("object"===("undefined"==typeof _ezim_d?"undefined":e(_ezim_d))&&_ezim_d.hasOwnProperty(t))return _ezim_d[t];for(var o in _ezim_d)if(o.split("/").pop()===t)return _ezim_d[o];return!1}(t);"object"==e(z)&&(void 0!==z.creative_id&&(g=z.creative_id),void 0!==z.line_item_id&&(l=z.line_item_id)),__ez.dot.isDefined(p,s)&&__ez.dot.isValid(o)&&("0"===p&&!0!==f||""===s||i.push({type:"impression",impression_id:p,domain_id:__ez.dot.getDID(),unit:s,t_epoch:__ez.dot.getEpoch(0),revenue:d,bid_floor_filled:n,stat_source_id:a,pageview_id:__ez.dot.getPageviewId(),comp_id:u,line_item_id:l,creative_id:g,data:__ez.dot.dataToStr(o),is_orig:f||__ez.template.isOrig}))}}function o(){void 0!==document.visibilityState&&"prerender"===document.visibilityState||(__ez.dot.isDefined(i)&&i.length>0&&[i.filter((function(e){return e.is_orig})),i.filter((function(e){return!e.is_orig}))].forEach((function(e){for(;e.length>0;){var i=e[0].is_orig||!1,t=5;t>e.length&&(t=e.length);var o=e.splice(0,t),d=__ez.dot.getURL("/porpoiseant/army.gif")+"?orig="+(!0===i?1:0)+"&sts="+btoa(JSON.stringify(o));(void 0!==window.isAmp&&isAmp||void 0!==window.ezWp&&ezWp)&&void 0!==window._ezaq&&_ezaq.hasOwnProperty("domain_id")&&(d+="&visit_uuid="+_ezaq.visit_uuid),__ez.dot.Fire(d)}})),i=[])}return{Add:t,AddAndFire:function(e,i){t(e,i,0,0,0,0,0),o()},AddAndFireOrig:function(e,i){t(e,i,0,0,0,0,0,!0),o()},AddById:function(e,t,o,d,_){var n=e.split("/");if(__ez.dot.isDefined(e)&&3===n.length&&__ez.dot.isValid(t)){var r=n[0],a={type:"impression",impression_id:n[2],domain_id:__ez.dot.getDID(),unit:r,t_epoch:__ez.dot.getEpoch(0),pageview_id:__ez.dot.getPageviewId(),data:__ez.dot.dataToStr(t),is_orig:o||__ez.template.isOrig};void 0!==d&&(a.revenue=d),void 0!==_&&(a.bid_floor_filled=_),i.push(a)}},Fire:o,GetPixels:function(){return i}}}()}();__ez.queue.addFile('/detroitchicago/raleigh.js', '/detroitchicago/raleigh.js?gcb=195-3&cb=6', false, ['/parsonsmaize/abilene.js'], true, false, true, false);__ez.queue.addFile('/detroitchicago/vista.js', '/detroitchicago/vista.js?gcb=195-3&cb=5', false, ['/parsonsmaize/abilene.js'], true, false, true, false);__ez.queue.addFile('/detroitchicago/tampa.js', '/detroitchicago/tampa.js?gcb=195-3&cb=5', false, ['/parsonsmaize/abilene.js'], true, false, true, false);</script><base href="/wiki/x86/avx512"/>

<title>Advanced Vector Extensions 512 (AVX-512) - x86 - WikiChip</title>
<script>document.documentElement.className = document.documentElement.className.replace( /(^|\s)client-nojs(\s|$)/, "$1client-js$2" );</script>
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":false,"wgNamespaceNumber":0,"wgPageName":"x86/avx-512","wgTitle":"x86/avx-512","wgCurRevisionId":101239,"wgRevisionId":101239,"wgArticleId":20932,"wgIsArticle":true,"wgIsRedirect":false,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["x86 extensions"],"wgBreakFrames":false,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"x86/avx-512","wgRelevantArticleId":20932,"wgRequestId":"bad7189192577da04e2c813b","wgIsProbablyEditable":true,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgRedirectedFrom":"x86/avx512","wgWikiEditorEnabledModules":{"toolbar":true,"dialogs":true,"preview":true,"publish":true},"wgPageFormsAutocompleteValues":[],"wgPageFormsAutocompleteOnAllChars":false,"wgPageFormsFieldProperties":[],"wgPageFormsCargoFields":[],"wgPageFormsDependentFields":[],"wgPageFormsGridValues":[],"wgPageFormsGridParams":[],"wgPageFormsShowOnSelect":[],"wgPageFormsScriptPath":"/w/extensions/PageForms","edgValues":null,"wgPageFormsEDSettings":null,"wgHeaderTabsTabIndexes":[],"wgCategoryTreePageCategoryOptions":"{\"mode\":0,\"hideprefix\":20,\"showcount\":true,\"namespaces\":false}","wgInternalRedirectTargetUrl":"/wiki/x86/avx-512"});mw.loader.state({"site.styles":"ready","noscript":"ready","user.styles":"ready","user.cssprefs":"ready","user":"ready","user.options":"loading","user.tokens":"loading","ext.cite.styles":"ready","ext.smw.style":"ready","ext.smw.tooltip.styles":"ready","mediawiki.skinning.interface":"ready","mediawiki.skinning.content.externallinks":"ready","skins.WikiChip2":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.sectionAnchor":"ready"});mw.loader.implement("user.options@0j3lz3q",function($,jQuery,require,module){mw.user.options.set({"variant":"en"});});mw.loader.implement("user.tokens@1glvl31",function ( $, jQuery, require, module ) {
mw.user.tokens.set({"editToken":"+\\","patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});/*@nomin*/;

});mw.loader.load(["mediawiki.action.view.redirect","ext.smw.style","mediawiki.page.startup"]);});</script>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.cite.styles%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.sectionAnchor%7Cmediawiki.skinning.content.externallinks%7Cmediawiki.skinning.interface%7Cskins.WikiChip2&amp;only=styles&amp;skin=WikiChip2"/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=ext.smw.style%7Cext.smw.tooltip.styles&amp;only=styles&amp;skin=WikiChip2"/>
<script async="" src="/w/load.php?debug=false&amp;lang=en&amp;modules=startup&amp;only=scripts&amp;skin=WikiChip2"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?debug=false&amp;lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=WikiChip2"/>
<meta name="generator" content="MediaWiki 1.28.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<link rel="ExportRDF" type="application/rdf+xml" title="x86/avx-512" href="/w/index.php?title=Special:ExportRDF/x86/avx-512&amp;xmlmime=rdf"/>
<link rel="alternate" type="application/x-wiki" title="Edit" href="/w/index.php?title=x86/avx-512&amp;action=edit"/>
<link rel="edit" title="Edit" href="/w/index.php?title=x86/avx-512&amp;action=edit"/>
<link rel="shortcut icon" href="/w/resources/assets/wikichip.png"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="WikiChip (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="/w/api.php?action=rsd"/>
<link rel="canonical" href="/wiki/x86/avx-512"/>
<meta name="twitter:site" content="@WikiChip"/>
<meta name="twitter:image" content="/w/resources/assets/og_wikichip_logo.png"/>
<meta property="og:image" content="/w/resources/assets/og_wikichip_logo.png"/>
<meta property="og:title" content="Advanced Vector Extensions 512 (AVX-512) - x86 - WikiChip"/>
<meta name="twitter:card" content="summary"/>
<meta property="og:type" content="article"/>
<meta property="twitter:description" content="Advanced Vector Extensions 512 (AVX-512) is collective name for a number of 512-bit SIMD x86 instruction set extensions. The extensions were formally introduced by Intel in July 2013 with first general-purpose microprocessors implementing the extensions introduced in July 2017."/>
<link href="https://fonts.googleapis.com/css?family=Roboto+Condensed" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/css?family=Josefin+Sans:400,700&amp;display=swap" rel="stylesheet"/>
<script type='text/javascript'>
var ezoTemplate = 'orig_site';
var ezouid = '1';
var ezoFormfactor = '1';
</script><script data-ezscrex="false" type='text/javascript'>
var soc_app_id = '0';
var did = 86609;
var ezdomain = 'wikichip.org';
var ezoicSearchable = 1;
</script>
<script data-ezscrex="false" type="text/javascript" data-cfasync="false">var _ezaq = window._ezaq = Object.assign({}, typeof window._ezaq !== "undefined" ? window._ezaq : {}, {"ab_test_id":"mod62","ad_cache_level":1,"ad_lazyload_version":0,"ad_load_version":0,"city":"Ashburn","country":"US","days_since_last_visit":-1,"domain_id":86609,"domain_test_group":20230808,"engaged_time_visit":0,"ezcache_level":0,"ezcache_skip_code":0,"form_factor_id":1,"framework_id":1,"has_bad_image":0,"has_bad_words":0,"is_embed":false,"is_return_visitor":false,"is_sitespeed":0,"last_page_load":"","last_pageview_id":"","lt_cache_level":0,"metro_code":511,"page_ad_positions":"","page_view_count":0,"page_view_id":"3fd855eb-21fc-4432-776c-0c5fdb58fd88","position_selection_id":0,"postal_code":"20149","pv_event_count":0,"response_size_orig":184083,"response_time_orig":225,"serverid":"i-015cb3fb534e78f16","state":"VA","t_epoch":1701805624,"template_id":5,"time_on_site_visit":0,"url":"/wiki/x86/avx512","word_count":11810,"worst_bad_word_level":0});var _ezExtraQueries = "&ez_orig=1";</script>
<script data-ezscrex='false' data-pagespeed-no-defer data-cfasync='false'>
function create_ezolpl() {
	var d = new Date();
	d.setTime(d.getTime() + (365*24*60*60*1000));
	var expires = "expires="+d.toUTCString();
	__ez.ck.setByCat("ezux_lpl_86609=" + new Date().getTime() + "|" + _ezaq.page_view_id + "|" + _ezaq.is_return_visitor + "; " + expires, 3);
}
function attach_ezolpl() {
	if (document.readyState === "complete") {
		create_ezolpl();
		return;
	}
	window.addEventListener("load", create_ezolpl);
}

__ez.queue.addFunc("attach_ezolpl", "attach_ezolpl", null, false, ['/detroitchicago/boise.js'], true, false, false, false);
</script></head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-x86_avx-512 rootpage-x86 skin-WikiChip2 action-view">
<div id="mw-wrapper">
<div class="mw-body" role="main">
<!-- wikichip-header START -->
<div id="wikichip-header">
            <div id="wikichip-header-logo">
                <a href="/wiki/WikiChip"><img src="//en.wikichip.org/w/resources/assets/wikichip_logo4.svg" width="200px"/></a><br/>
                <span id="tagline">Semiconductor &amp; Computer Engineering</span>
            </div>
	    <div id="wikichip-aheader">
		<!-- Ezoic - wikichip/global/header - top_of_page -->
		<div id="ezoic-pub-ad-placeholder-138">
                <script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
                <ins class="adsbygoogle" style="display:block;" data-ad-client="ca-pub-1951113009523412" data-ad-slot="1822985275" data-ad-format="auto"></ins>
                <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
		</div>
		<!-- End Ezoic - wikichip/global/header - top_of_page -->
            </div>
</div>
<!-- wikichip-header END -->
<!-- wikichip-main-menu START -->
<ul id="wikichip-main-menu">
	<li class="btn">
        <a class="btnllnk"><i class="fa fa-home" aria-hidden="true"></i><span class="mob-collapse"> WikiChip <i class="fa fa-angle-down" aria-hidden="true"></i></span></a>
        <div class="collapse">
            <div>
                <span class="wikichip-main-menu-header">WikiChip</span>
                <hr/>
                <div style="display: flex;">
                    <ul class="items">
                        <li>
                                <h5><a href="/wiki/WikiChip">WikiChip</a></h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/WikiChip">Home</a></li>
                                    <li><a href="/wiki/Special:Random?nocache=1" title="Load a random page [alt-shift-x]" accesskey="x">Random Article</a></li>
                                    <li><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [alt-shift-r]" accesskey="r">Recent Changes</a></li>
                                    <li><a href="/wiki/WikiChip:chip_feed">Chip Feed</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5><a href="https://fuse.wikichip.org/">The Fuse Coverage</a></h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="https://fuse.wikichip.org/">Recent News</a></li>
                                    <li><a href="https://fuse.wikichip.org/news/category/conferences/isscc/">ISSCC</a></li>
                                    <li><a href="https://fuse.wikichip.org/news/category/conferences/iedm/">IEDM</a></li>
                                    <li><a href="https://fuse.wikichip.org/news/category/conferences/vlsi/">VLSI</a></li>
                                    <li><a href="https://fuse.wikichip.org/news/category/conferences/hot-chips/">Hot Chips</a></li>
                                    <li><a href="https://fuse.wikichip.org/news/category/conferences/supercomputing/">SuperComputing</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Social Media</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="https://twitter.com/WikiChip" rel="nofollow">Twitter</a></li>
                                    <li><a href="https://flipboard.com/@WikiChip" rel="nofollow">Flipboard</a></li>
                                </ul>
                        </li>
                    </ul>
                </div>
            </div>
            <div>
                <span class="wikichip-main-menu-header">Popular</span>
                <hr/>
                <div style="display: flex;">
                    <ul class="items">
                        <li>
                                <h5>Companies</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/intel">Intel</a></li>
                                    <li><a href="/wiki/amd">AMD</a></li>
                                    <li><a href="/wiki/arm_holdings">ARM</a></li>
                                    <li><a href="/wiki/qualcomm">Qualcomm</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Microarchitectures</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/intel/microarchitectures/skylake_(client)">Skylake (Client)</a></li>
                                    <li><a href="/wiki/intel/microarchitectures/skylake_(server)">Skylake (Server)</a></li>
                                    <li><a href="/wiki/amd/microarchitectures/zen">Zen</a></li>
                                    <li><a href="/wiki/intel/microarchitectures/coffee_lake">Coffee Lake</a></li>
                                    <li><a href="/wiki/amd/microarchitectures/zen_2">Zen 2</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5><a href="/wiki/technology_node">Technology Nodes</a></h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/14_nm_lithography_process">14 nm</a></li>
                                    <li><a href="/wiki/10_nm_lithography_process">10 nm</a></li>
                                    <li><a href="/wiki/7_nm_lithography_process">7 nm</a></li>
                                </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
	</li>
	<li class="btn">
        <a class="btnllnk">
            <i class="fa fa-architecture" aria-hidden="true"></i><span class="mob-collapse"> Architectures <i class="fa fa-angle-down" aria-hidden="true"></i></span></a>
        <div class="collapse">
            <div>
                <span class="wikichip-main-menu-header">Popular x86</span>
                <hr/>
                <div style="display: flex;">
                    <ul class="items">
                        <li>
                                <h5>Intel</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li>
                                        Client
                                        <ul>
                                            <li><a href="/wiki/intel/microarchitectures/skylake_(client)">Skylake</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/kaby_lake">Kaby Lake</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/coffee_lake">Coffee Lake</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/ice_lake_(client)">Ice Lake</a></li>
                                        </ul>
                                    </li>
                                    <li>
                                        Server
                                        <ul>
                                            <li><a href="/wiki/intel/microarchitectures/skylake_(server)">Skylake</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/cascade_lake">Cascade Lake</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/cooper_lake">Cooper Lake</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/ice_lake_(server)">Ice Lake</a></li>
                                        </ul>
                                    </li>
                                    <li>
                                        Big Cores
                                        <ul>
                                            <li><a href="/wiki/intel/microarchitectures/sunny_cove">Sunny Cove</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/willow_cove">Willow Cove</a></li>
                                        </ul>
                                    </li>
                                    <li>
                                        Small Cores
                                        <ul>
                                            <li><a href="/wiki/intel/microarchitectures/goldmont">Goldmont</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/goldmont_plus">Goldmont Plus</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/tremont">Tremont</a></li>
                                            <li><a href="/wiki/intel/microarchitectures/gracemont">Gracemont</a></li>
                                        </ul>
                                    </li>
                                </ul>
                        </li>
                        <li>
                                <h5>AMD</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/amd/microarchitectures/zen">Zen</a></li>
                                    <li><a href="/wiki/amd/microarchitectures/zen_+">Zen+</a></li>
                                    <li><a href="/wiki/amd/microarchitectures/zen_2">Zen 2</a></li>
                                    <li><a href="/wiki/amd/microarchitectures/zen_3">Zen 3</a></li>
                                </ul>
                        </li>
                    </ul>
                </div>
            </div>
            <div>
                <span class="wikichip-main-menu-header">Popular ARM</span>
                <hr/>
                <div style="display: flex;">
                    <ul class="items">
                        <li>
                                <h5>ARM</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li>
                                        Server
                                        <ul>
                                            <li><a href="/wiki/arm_holdings/microarchitectures/neoverse n1">Neoverse N1</a></li>
                                            <li><a href="/wiki/arm_holdings/microarchitectures/zeus">Zeus</a></li>
                                        </ul>
                                    </li>
                                    <li>
                                        Big
                                        <ul><!--
                                            <li><a href="/wiki/arm_holdings/microarchitectures/cortex-a72">Cortex-A72</a></li>
                                            <li><a href="/wiki/arm_holdings/microarchitectures/cortex-a73">Cortex-A73</a></li>-->
					    <li><a href="/wiki/arm_holdings/microarchitectures/cortex-a75">Cortex-A75</a></li>

                                            <li><a href="/wiki/arm_holdings/microarchitectures/cortex-a76">Cortex-A76</a></li>
                                            <li><a href="/wiki/arm_holdings/microarchitectures/cortex-a77">Cortex-A77</a></li>
                                        </ul>
                                    </li>
                                    <li>
                                        Little
                                        <ul>
                                            <li><a href="/wiki/arm_holdings/microarchitectures/cortex-a53">Cortex-A53</a></li>
                                            <li><a href="/wiki/arm_holdings/microarchitectures/cortex-a55">Cortex-A55</a></li>
                                        </ul>
                                    </li>
                                </ul>
                        </li>
                        <li>
                                <h5>Cavium</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/cavium/microarchitectures/vulcan">Vulcan</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Samsung</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/samsung/microarchitectures/m1">Exynos M1</a></li>
                                    <li><a href="/wiki/samsung/microarchitectures/m2">Exynos M2</a></li>
                                    <li><a href="/wiki/samsung/microarchitectures/m3">Exynos M3</a></li>
                                    <li><a href="/wiki/samsung/microarchitectures/m4">Exynos M4</a></li>
                                </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </li>
	<li class="btn">
        <a class="btnllnk"><i class="fa fa-microchip" aria-hidden="true"></i><span class="mob-collapse"> Chips <i class="fa fa-angle-down" aria-hidden="true"></i></span></a>

        <div class="collapse">
            <div>
                <span class="wikichip-main-menu-header">Popular Families</span>
                <hr/>
                <div style="display: flex;">
                    <ul class="items">
                        <li>
                                <h5>Intel</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/intel/core_i3">Core i3</a></li>
                                    <li><a href="/wiki/intel/core_i5">Core i5</a></li>
                                    <li><a href="/wiki/intel/core_i7">Core i7</a></li>
                                    <li><a href="/wiki/intel/core_i9">Core i9</a></li>
                                    <li><a href="/wiki/intel/xeon_d">Xeon D</a></li>
                                    <li><a href="/wiki/intel/xeon_e">Xeon E</a></li>
                                    <li><a href="/wiki/intel/xeon_w">Xeon W</a></li>
                                    <li><a href="/wiki/intel/xeon_bronze">Xeon Bronze</a></li>
                                    <li><a href="/wiki/intel/xeon_silver">Xeon Silver</a></li>
                                    <li><a href="/wiki/intel/xeon_gold">Xeon Gold</a></li>
                                    <li><a href="/wiki/intel/xeon_platinum">Xeon Platinum</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>AMD</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/amd/ryzen_3">Ryzen 3</a></li>
                                    <li><a href="/wiki/amd/ryzen_5">Ryzen 5</a></li>
                                    <li><a href="/wiki/amd/ryzen_7">Ryzen 7</a></li>
                                    <li><a href="/wiki/amd/ryzen_threadripper">Ryzen Threadripper</a></li>
                                    <li><a href="/wiki/amd/epyc">EPYC</a></li>
                                    <li><a href="/wiki/amd/epyc_embedded">EPYC Embedded</a></li>
                                </ul>
                        </li>
                    </ul>
                </div>
            </div>
            <div>
                <div style="display: flex;">
                    <ul class="items">
                        <li>
                                <h5>Ampere</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/ampere_computing/emag">eMAG</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Apple</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/apple/ax">Ax</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Cavium</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/cavium/thunderx">ThunderX</a></li>
                                    <li><a href="/wiki/cavium/thunderx2">ThunderX2</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>HiSilicon</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/hisilicon/kirin">Kirin</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>MediaTek</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/mediatek/helio">Helio</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>NXP</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="">i.MX</a></li>
                                    <li><a href="">QorIQ Layerscape</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Qualcomm</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="">Snapdragon 400</a></li>
                                    <li><a href="">Snapdragon 600</a></li>
                                    <li><a href="">Snapdragon 700</a></li>
                                    <li><a href="">Snapdragon 800</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Renesas</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/renesas/r-car">R-Car</a></li>
                                </ul>
                        </li>
                        <li>
                                <h5>Samsung</h5>
                                <ul style="list-style:none; display: flex; flex-direction: column;">
                                    <li><a href="/wiki/samsung/exynos">Exynos</a></li>
                                </ul>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
	</li>

	<li class="input-search">
                <form class="mw-portlet" role="search" action="/w/index.php" id="p-search">
                        <input type="hidden" value="Special:Search" name="title"/>
                        <input type="search" name="search" class="form-control" placeholder="chip, part #, µarch, family, etc" title="Search WikiChip [alt-shift-f]" accesskey="f" id="searchInput" autocomplete="off"/>
                        <button type="submit" name="go" title="Go to the page by that name or part # if it exists"><i class="fa fa-search" aria-hidden="true"></i></button>
</form>
	</li>
</ul>
<!-- wikichip-main-menu END -->
<!-- wikichip-body-container START -->
<div class="wikichip-body-container">
<!-- mw-body-content enclosure START -->
<div id="wikichip-body-content">
<!-- mw-body-content START -->
<div class="mw-body-content">
                                <div id="siteSub">From WikiChip</div>					
<div id="article-title">
<nav id="primary_nav_wrap">
<ul>
<li><a><span class="mob-collapse"><i class="fa fa-file-o" aria-hidden="true"></i></span></a><ul><li class="selected"><a href="/wiki/x86/avx-512">Page</a></li></ul></li><li class=""><a href="/wiki/Talk:x86/avx-512"><i class="fa fa-comments" aria-hidden="true"></i></a></li>

  <li class=""><a href="/w/index.php?title=x86/avx-512&amp;action=edit" title="Edit this page [alt-shift-e]" accesskey="e"><i class="fa fa-edit" aria-hidden="true"></i></a></li><li class=""><a href="/w/index.php?title=x86/avx-512&amp;action=history"><i class="fa fa-history" aria-hidden="true"></i></a></li>

            <li><a><i class="fa fa-user-circle-o" aria-hidden="true"></i></a><ul><li class="pt-anontalk pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [alt-shift-n]" accesskey="n"><i class="fa fa-users" aria-hidden="true"></i> Talk</a></li><li class="pt-anoncontribs pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [alt-shift-y]" accesskey="y"><i class="fa fa-list" aria-hidden="true"></i> Contributions</a></li><li class="pt-login pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=x86%2Favx-512"><i class="fa fa-sign-in" aria-hidden="true"></i> Log in</a></li>		</ul>
	</li>



<li><a><i class="fa fa-cogs" aria-hidden="true"></i></a>
<ul>
<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/x86/avx-512"><i class="fa fa-map" aria-hidden="true"></i> What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/x86/avx-512"><i class="fa fa-list" aria-hidden="true"></i> Related changes</a></li><li id="t-print"><a href="/w/index.php?title=x86/avx-512&amp;printable=yes"><i class="fa fa-file-text-o" aria-hidden="true"></i> Printable version</a></li><li id="t-permalink"><a href="/w/index.php?title=x86/avx-512&amp;oldid=101239"><i class="fa fa-link" aria-hidden="true"></i> Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=x86/avx-512&amp;action=info"><i class="fa fa-info-circle" aria-hidden="true"></i> Page information</a></li><li id="t-smwbrowselink"><a href="/wiki/Special:Browse/:x86-2Favx-2D512"><i class="fa fa-tasks" aria-hidden="true"></i> Browse properties</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages"><i class="fa fa-certificate" aria-hidden="true"></i> Special Pages</a></li></ul>
</li>
<li><a><i class="fa fa-wheelchair" aria-hidden="true"></i></a>
  <ul>
    <li><a id="wikichip-dec-font"><img src="//en.wikichip.org/w/resources/assets/wikichip/a minus.svg" alt="Decrease Font Size" width="14"/> Decrease Size</a></li>
    <li><a id="wikichip-inc-font"><img src="//en.wikichip.org/w/resources/assets/wikichip/a plus.svg" alt="Increase Font Size" width="14"/> Increase Size</a></li>
    <li><a id="wikichip-std-font"><i class="fa fa-font" aria-hidden="true"></i> Normal Size</a></li>
  </ul>
</li>

</ul></nav>

    Advanced Vector Extensions 512 (AVX-512) - x86    <span id="article-indicator"><div class="mw-indicators">
</div>
</span>
</div>


                <div id="article-breadcrumbs">
                    <span class="pull-left"><span class="subpages">&lt; <a href="/wiki/x86" title="x86">x86</a></span><span class="mw-redirectedfrom">(Redirected from <a href="/w/index.php?title=x86/avx512&amp;redirect=no" class="mw-redirect" title="x86/avx512">x86/avx512</a>)</span></span>
                </div>	
														<p></p><div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="guidebox">
<div style="text-align: center;"><a href="/wiki/x86" title="x86"><span style="color: rgba(0,0,0,.53); text-shadow: 0px 2px 3px rgba(0,0,0,.33); font-size: 20pt; font-weight: bold;">x86</span></a><br/><b>Instruction Set Architecture</b></div>
<div class="header">General</div>
<ul><li> <a href="/w/index.php?title=x86/history&amp;action=edit&amp;redlink=1" class="new" title="x86/history (page does not exist)">History</a></li>
<li> <a href="/wiki/x86/list_of_processor_families" title="x86/list of processor families">Families</a></li></ul>
<div class="header">Variants</div>
<ul><li> <a href="/w/index.php?title=x86/x86-16&amp;action=edit&amp;redlink=1" class="new" title="x86/x86-16 (page does not exist)">x86-16</a></li>
<li> <a href="/w/index.php?title=x86/x86-32&amp;action=edit&amp;redlink=1" class="new" title="x86/x86-32 (page does not exist)">x86-32</a></li>
<li> <a href="/w/index.php?title=x86/x86-64&amp;action=edit&amp;redlink=1" class="new" title="x86/x86-64 (page does not exist)">x86-64</a></li></ul>
<div class="header">Topics</div>
<ul><li> <a href="/w/index.php?title=x86/instruction_listing&amp;action=edit&amp;redlink=1" class="new" title="x86/instruction listing (page does not exist)">Instructions</a></li>
<li> <a href="/w/index.php?title=x86/addressing_modes&amp;action=edit&amp;redlink=1" class="new" title="x86/addressing modes (page does not exist)">Addressing Modes</a></li>
<li> <a href="/w/index.php?title=x86/registers&amp;action=edit&amp;redlink=1" class="new" title="x86/registers (page does not exist)">Registers</a></li>
<li> <a href="/w/index.php?title=x86/model-specific_register&amp;action=edit&amp;redlink=1" class="new" title="x86/model-specific register (page does not exist)">Model-Specific Register</a></li>
<li> <a href="/w/index.php?title=x86/assembly&amp;action=edit&amp;redlink=1" class="new" title="x86/assembly (page does not exist)">Assembly</a></li>
<li> <a href="/w/index.php?title=x86/interrupts&amp;action=edit&amp;redlink=1" class="new" title="x86/interrupts (page does not exist)">Interrupts</a></li>
<li> <a href="/w/index.php?title=x86/micro-ops&amp;action=edit&amp;redlink=1" class="new" title="x86/micro-ops (page does not exist)">Micro-Ops</a></li>
<li> <a href="/w/index.php?title=x86/timer&amp;action=edit&amp;redlink=1" class="new" title="x86/timer (page does not exist)">Timer</a></li>
<li> <a href="/w/index.php?title=x86/calling_convention&amp;action=edit&amp;redlink=1" class="new" title="x86/calling convention (page does not exist)">Calling Convention</a></li>
<li> <a href="/w/index.php?title=x86/microarchitectures&amp;action=edit&amp;redlink=1" class="new" title="x86/microarchitectures (page does not exist)">Microarchitectures</a></li>
<li> <a href="/w/index.php?title=x86/cpuid&amp;action=edit&amp;redlink=1" class="new" title="x86/cpuid (page does not exist)">CPUID</a></li></ul>
<div class="header">CPUIDs</div>
<ul><li> <a href="/wiki/amd/cpuid" title="amd/cpuid">AMD&#39;s CPUIDs</a></li>
<li> <a href="/wiki/intel/cpuid" title="intel/cpuid">Intel&#39;s CPUIDs</a></li></ul>
<div class="header">Modes</div>
<ul><li> <a href="/w/index.php?title=x86/real_mode&amp;action=edit&amp;redlink=1" class="new" title="x86/real mode (page does not exist)">Real</a></li>
<li> <a href="/w/index.php?title=x86/protected_mode&amp;action=edit&amp;redlink=1" class="new" title="x86/protected mode (page does not exist)">Protected</a></li>
<li> <a href="/w/index.php?title=x86/long_mode&amp;action=edit&amp;redlink=1" class="new" title="x86/long mode (page does not exist)">Long</a></li></ul>
<div class="header">Extensions<small style="float: right;">(<a href="/wiki/x86/extensions" title="x86/extensions">all</a>)</small></div>
<div class="wiki-ul-col3">
<ul><li> <a href="/w/index.php?title=x86/3dnow!&amp;action=edit&amp;redlink=1" class="new" title="x86/3dnow! (page does not exist)">3DNow!</a></li>
<li> <a href="/w/index.php?title=x86/abm&amp;action=edit&amp;redlink=1" class="new" title="x86/abm (page does not exist)">ABM</a></li>
<li> <a href="/wiki/x86/adx" title="x86/adx">ADX</a></li>
<li> <a href="/w/index.php?title=x86/aes&amp;action=edit&amp;redlink=1" class="new" title="x86/aes (page does not exist)">AES</a></li>
<li> <a href="/wiki/x86/amx" title="x86/amx">AMX</a></li>
<li> <a href="/w/index.php?title=x86/avx&amp;action=edit&amp;redlink=1" class="new" title="x86/avx (page does not exist)">AVX</a></li>
<li> <a href="/w/index.php?title=x86/avx2&amp;action=edit&amp;redlink=1" class="new" title="x86/avx2 (page does not exist)">AVX2</a></li>
<li> <strong class="selflink">AVX-512</strong></li>
<li> <a href="/w/index.php?title=x86/bmi1&amp;action=edit&amp;redlink=1" class="new" title="x86/bmi1 (page does not exist)">BMI1</a></li>
<li> <a href="/w/index.php?title=x86/bmi2&amp;action=edit&amp;redlink=1" class="new" title="x86/bmi2 (page does not exist)">BMI2</a></li>
<li> <a href="/w/index.php?title=x86/clmul&amp;action=edit&amp;redlink=1" class="new" title="x86/clmul (page does not exist)">CLMUL</a></li>
<li> <a href="/w/index.php?title=x86/e3dnow!&amp;action=edit&amp;redlink=1" class="new" title="x86/e3dnow! (page does not exist)">E3DNow!</a></li>
<li> <a href="/w/index.php?title=x86/emmx&amp;action=edit&amp;redlink=1" class="new" title="x86/emmx (page does not exist)">EMMX</a></li>
<li> <a href="/w/index.php?title=x86/f16c&amp;action=edit&amp;redlink=1" class="new" title="x86/f16c (page does not exist)">F16C</a></li>
<li> <a href="/w/index.php?title=x86/fma3&amp;action=edit&amp;redlink=1" class="new" title="x86/fma3 (page does not exist)">FMA3</a></li>
<li> <a href="/w/index.php?title=x86/fma4&amp;action=edit&amp;redlink=1" class="new" title="x86/fma4 (page does not exist)">FMA4</a></li>
<li> <a href="/w/index.php?title=x86/fpu&amp;action=edit&amp;redlink=1" class="new" title="x86/fpu (page does not exist)">FPU</a></li>
<li> <a href="/wiki/x86/mktme" class="mw-redirect" title="x86/mktme">MKTME</a></li>
<li> <a href="/w/index.php?title=x86/mmx&amp;action=edit&amp;redlink=1" class="new" title="x86/mmx (page does not exist)">MMX</a></li>
<li> <a href="/w/index.php?title=x86/mpx&amp;action=edit&amp;redlink=1" class="new" title="x86/mpx (page does not exist)">MPX</a></li>
<li> <a href="/wiki/x86/persistent_memory_extensions" title="x86/persistent memory extensions">PMEM</a></li>
<li> <a href="/w/index.php?title=x86/prefetch&amp;action=edit&amp;redlink=1" class="new" title="x86/prefetch (page does not exist)">PREFETCH</a></li>
<li> <a href="/w/index.php?title=x86/rdrand&amp;action=edit&amp;redlink=1" class="new" title="x86/rdrand (page does not exist)">RdRAND</a></li>
<li> <a href="/w/index.php?title=x86/sev&amp;action=edit&amp;redlink=1" class="new" title="x86/sev (page does not exist)">SEV</a></li>
<li> <a href="/w/index.php?title=x86/sgx&amp;action=edit&amp;redlink=1" class="new" title="x86/sgx (page does not exist)">SGX</a></li>
<li> <a href="/w/index.php?title=x86/sha&amp;action=edit&amp;redlink=1" class="new" title="x86/sha (page does not exist)">SHA</a></li>
<li> <a href="/wiki/x86/sme" title="x86/sme">SME</a></li>
<li> <a href="/w/index.php?title=x86/smm&amp;action=edit&amp;redlink=1" class="new" title="x86/smm (page does not exist)">SMM</a></li>
<li> <a href="/w/index.php?title=x86/smx&amp;action=edit&amp;redlink=1" class="new" title="x86/smx (page does not exist)">SMX</a></li>
<li> <a href="/w/index.php?title=x86/sse&amp;action=edit&amp;redlink=1" class="new" title="x86/sse (page does not exist)">SSE</a></li>
<li> <a href="/w/index.php?title=x86/sse2&amp;action=edit&amp;redlink=1" class="new" title="x86/sse2 (page does not exist)">SSE2</a></li>
<li> <a href="/w/index.php?title=x86/sse3&amp;action=edit&amp;redlink=1" class="new" title="x86/sse3 (page does not exist)">SSE3</a></li>
<li> <a href="/w/index.php?title=x86/sse4.1&amp;action=edit&amp;redlink=1" class="new" title="x86/sse4.1 (page does not exist)">SSE4.1</a></li>
<li> <a href="/w/index.php?title=x86/sse4.2&amp;action=edit&amp;redlink=1" class="new" title="x86/sse4.2 (page does not exist)">SSE4.2</a></li>
<li> <a href="/w/index.php?title=x86/sse4a&amp;action=edit&amp;redlink=1" class="new" title="x86/sse4a (page does not exist)">SSE4a</a></li>
<li> <a href="/w/index.php?title=x86/sse5&amp;action=edit&amp;redlink=1" class="new" title="x86/sse5 (page does not exist)">SSE5</a></li>
<li> <a href="/w/index.php?title=x86/ssse3&amp;action=edit&amp;redlink=1" class="new" title="x86/ssse3 (page does not exist)">SSSE3</a></li>
<li> <a href="/w/index.php?title=x86/tbm&amp;action=edit&amp;redlink=1" class="new" title="x86/tbm (page does not exist)">TBM</a></li>
<li> <a href="/wiki/x86/tme" title="x86/tme">TME</a></li>
<li> <a href="/wiki/x86/tsme" class="mw-redirect" title="x86/tsme">TSME</a></li>
<li> <a href="/w/index.php?title=x86/tsx&amp;action=edit&amp;redlink=1" class="new" title="x86/tsx (page does not exist)">TSX</a></li>
<li> <a href="/w/index.php?title=x86/xop&amp;action=edit&amp;redlink=1" class="new" title="x86/xop (page does not exist)">XOP</a></li></ul>
</div><span class="noprint plainlinks navbar" style="float:right;"><small><span style="white-space:nowrap;word-spacing:-.12em;"><a href="/wiki/Template:x86_isa_main" title="Template:x86 isa main"><span style="" title="View this template">v</span></a><span style=""> <b>·</b> </span><a href="/wiki/Template:x86_isa_main" title="Template:x86 isa main"><span style="" title="Discuss this template">d</span></a><span style=""> <b>·</b> </span><a rel="nofollow" class="external text" href="/w/index.php?title=Template:x86_isa_main&amp;action=edit"><span style="" title="Edit this template">e</span></a></span></small></span>
</div>
<p><b>Advanced Vector Extensions 512</b> (<b>AVX-512</b>) is collective name for a number of <a href="/w/index.php?title=512-bit_architecture&amp;action=edit&amp;redlink=1" class="new" title="512-bit architecture (page does not exist)">512-bit</a> <a href="/w/index.php?title=SIMD&amp;action=edit&amp;redlink=1" class="new" title="SIMD (page does not exist)">SIMD</a> <a href="/wiki/x86" title="x86">x86</a> <a href="/w/index.php?title=instruction_set&amp;action=edit&amp;redlink=1" class="new" title="instruction set (page does not exist)">instruction set</a> extensions. The <a href="/wiki/x86/extensions" title="x86/extensions">extensions</a> were formally introduced by <a href="/wiki/Intel" class="mw-redirect" title="Intel">Intel</a> in July <a href="/wiki/2013" title="2013">2013</a> with first general-purpose microprocessors implementing the extensions introduced in July <a href="/wiki/2017" title="2017">2017</a>.
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#Overview"><span class="tocnumber">1</span> <span class="toctext">Overview</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Registers"><span class="tocnumber">2</span> <span class="toctext">Registers</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Write_masking"><span class="tocnumber">3</span> <span class="toctext">Write masking</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#Memory_fault_suppression"><span class="tocnumber">4</span> <span class="toctext">Memory fault suppression</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Integer_instructions"><span class="tocnumber">5</span> <span class="toctext">Integer instructions</span></a></li>
<li class="toclevel-1 tocsection-6"><a href="#Floating_point_instructions"><span class="tocnumber">6</span> <span class="toctext">Floating point instructions</span></a></li>
<li class="toclevel-1 tocsection-7"><a href="#Mask_register_instructions"><span class="tocnumber">7</span> <span class="toctext">Mask register instructions</span></a></li>
<li class="toclevel-1 tocsection-8"><a href="#Detection"><span class="tocnumber">8</span> <span class="toctext">Detection</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Implementation"><span class="tocnumber">9</span> <span class="toctext">Implementation</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Documents"><span class="tocnumber">11</span> <span class="toctext">Documents</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="Overview">Overview</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=1" title="Edit section: Overview">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>AVX-512 is a set of <a href="/w/index.php?title=512-bit_architecture&amp;action=edit&amp;redlink=1" class="new" title="512-bit architecture (page does not exist)">512-bit</a> <a href="/w/index.php?title=SIMD&amp;action=edit&amp;redlink=1" class="new" title="SIMD (page does not exist)">SIMD</a> extensions that allow programs to pack sixteen <a href="/w/index.php?title=single-precision&amp;action=edit&amp;redlink=1" class="new" title="single-precision (page does not exist)">single-precision</a> eight <a href="/w/index.php?title=double-precision&amp;action=edit&amp;redlink=1" class="new" title="double-precision (page does not exist)">double-precision</a> <a href="/w/index.php?title=floating-point&amp;action=edit&amp;redlink=1" class="new" title="floating-point (page does not exist)">floating-point</a> numbers, or eight 64-bit or sixteen 32-bit integers within 512-bit vectors. The extension provides double the computation capabilities of that of <a href="/w/index.php?title=x86/avx&amp;action=edit&amp;redlink=1" class="new" title="x86/avx (page does not exist)">AVX</a>/<a href="/w/index.php?title=x86/av2&amp;action=edit&amp;redlink=1" class="new" title="x86/av2 (page does not exist)">AV2</a>.
</p>
<dl><dt> <b>AVX512F</b> - <a href="/w/index.php?title=x86/avx512f&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512f (page does not exist)"><b>AVX-512 Foundation</b></a></dt>
<dd> Base of the 512-bit SIMD instruction extensions which is a comprehensive list of features for most HPC and enterprise applications. AVX-512 Foundation is the natural extensions to AVX/AVX2 which is extended using the <a href="/w/index.php?title=x86/evex&amp;action=edit&amp;redlink=1" class="new" title="x86/evex (page does not exist)">EVEX</a> prefix which builds on the existing <a href="/w/index.php?title=x86/vex&amp;action=edit&amp;redlink=1" class="new" title="x86/vex (page does not exist)">VEX</a> prefix. Any processor that implements any portion of the AVX-512 extensions MUST implement AVX512F.</dd></dl>
<dl><dt> <b>AVX512CD</b> - <a href="/w/index.php?title=x86/avx512cd&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512cd (page does not exist)"><b>AVX-512 Conflict Detection Instructions</b></a></dt>
<dd> Enables vectorization of loops with possible address conflict.</dd></dl>
<dl><dt> <b>AVX512PF</b> - <a href="/w/index.php?title=x86/avx512pf&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512pf (page does not exist)"><b>AVX-512 Prefetch Instructions</b></a></dt>
<dd> Adds new prefetch instructions matching the gather/scatter instructions introduced by AVX512F.</dd></dl>
<dl><dt> <b>AVX512ER</b> - <a href="/w/index.php?title=x86/avx512er&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512er (page does not exist)"><b>AVX-512 Exponential and Reciprocal Instructions</b></a> (<b>ERI</b>)</dt>
<dd> Doubles the precision of the RCP, RSQRT and EXP2 approximation instructions from 14 to 28 bits.</dd></dl>
<dl><dt> <b>AVX512BW</b> - <a href="/w/index.php?title=x86/avx512bw&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512bw (page does not exist)"><b>AVX-512 Byte and Word Instructions</b></a></dt>
<dd> Adds new and supplemental 8-bit and 16-bit integer instructions, mostly promoting legacy AVX and AVX-512 instructions.</dd></dl>
<dl><dt> <b>AVX512DQ</b> - <a href="/wiki/x86/avx512dq" title="x86/avx512dq"><b>AVX-512 Doubleword and Quadword Instructions</b></a></dt>
<dd> Adds new and supplemental 32-bit and 64-bit integer and floating point instructions.</dd></dl>
<dl><dt> <b>AVX512VL</b> - <b>AVX-512 Vector Length</b></dt>
<dd> Adds vector length orthogonality. This is not an extension so much as a feature flag indicating that the supported AVX-512 instructions operating on 512-bit vectors can also operate on 128- and 256-bit vectors like <a href="/w/index.php?title=x86/sse&amp;action=edit&amp;redlink=1" class="new" title="x86/sse (page does not exist)">SSE</a> and <a href="/w/index.php?title=x86/avx&amp;action=edit&amp;redlink=1" class="new" title="x86/avx (page does not exist)">AVX</a> instructions. </dd></dl>
<dl><dt> <b>AVX512_IFMA</b> - <a href="/wiki/x86/avx512_ifma" title="x86/avx512 ifma"><b>AVX-512 Integer Fused Multiply-Add</b></a></dt>
<dd> Fused multiply-add of 52-bit integers.</dd></dl>
<dl><dt> <b>AVX512_VBMI</b> - <a href="/wiki/x86/avx512_vbmi" title="x86/avx512 vbmi"><b>AVX-512 Vector Bit Manipulation Instructions</b></a></dt>
<dd> Byte permutation instructions, including one shifting unaligned bytes.</dd></dl>
<dl><dt> <b>AVX512_VBMI2</b> - <a href="/wiki/x86/avx512_vbmi2" title="x86/avx512 vbmi2"><b>AVX-512 Vector Bit Manipulation Instructions 2</b></a></dt>
<dd> Bytewise compress/expand instructions and bitwise funnel shifts.</dd></dl>
<dl><dt> <b>AVX512_BITALG</b> - <a href="/wiki/x86/avx512_bitalg" title="x86/avx512 bitalg"><b>AVX-512 Bit Algorithms</b></a></dt>
<dd> Parallel population count in bytes or words and a bit shuffle instruction.</dd></dl>
<dl><dt> <b>AVX512_VPOPCNTDQ</b> - <a href="/wiki/x86/avx512_vpopcntdq" class="mw-redirect" title="x86/avx512 vpopcntdq"><b>AVX-512 Vector Population Count Doubleword and Quadword</b></a></dt>
<dd> Parallel population count in doublewords or quadwords.</dd></dl>
<dl><dt> <b>AVX512_4FMAPS</b> - <a href="/wiki/x86/avx512_4fmaps" title="x86/avx512 4fmaps"><b>AVX-512 Fused Multiply-Accumulate Packed Single Precision</b></a></dt>
<dd> Floating-point single precision multiply-accumulate, four iterations, instructions for deep learning.</dd></dl>
<dl><dt> <b>AVX512_4VNNIW</b> - <a href="/wiki/x86/avx512_4vnniw" title="x86/avx512 4vnniw"><b>AVX-512 Vector Neural Network Instructions Word Variable Precision</b></a></dt>
<dd> 16-bit integer multiply-accumulate, four iterations, instructions for deep learning.</dd></dl>
<dl><dt> <b>AVX512_FP16</b> - <a href="/w/index.php?title=x86/avx512_fp16&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512 fp16 (page does not exist)"><b>AVX-512 FP16 Instructions</b></a></dt>
<dd> Adds support for 16-bit half precision floating point values, promoting nearly all floating point instructions introduced by AVX512F.</dd></dl>
<dl><dt> <b>AVX512_BF16</b> - <a href="/wiki/x86/avx512_bf16" title="x86/avx512 bf16"><b>AVX-512 BFloat16 Instructions</b></a></dt>
<dd> <a href="/wiki/bfloat16" class="mw-redirect" title="bfloat16">BFloat16</a> multiply-add and conversion instructions for deep learning.</dd></dl>
<dl><dt> <b>AVX512_VNNI</b> - <a href="/wiki/x86/avx512_vnni" title="x86/avx512 vnni"><b>AVX-512 Vector Neural Network Instructions</b></a></dt>
<dd> 8- and 16-bit multiply-add instructions for deep learning.</dd></dl>
<dl><dt> <b>AVX512_VP2INTERSECT</b> - <a href="/w/index.php?title=x86/avx512_vp2intersect&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512 vp2intersect (page does not exist)"><b>AVX-512 Intersect Instructions</b></a></dt>
<dd> ...</dd></dl>
<p>The following extensions add instructions in AVX-512, AVX, and (in the case of GFNI) SSE versions and may be available on x86 CPUs without AVX-512 or even AVX support.
</p>
<dl><dt> <b>VAES</b> - <a href="/wiki/x86/vaes" title="x86/vaes"><b>Vector AES Instructions</b></a></dt>
<dd> Parallel <a href="http://en.wikipedia.org/wiki/Advanced_Encryption_Standard" class="extiw" title="wikipedia:Advanced Encryption Standard">AES</a> decoding and encoding instructions. Expands the earlier AESNI extension, which adds SSE and AVX versions of these instructions operating on 128-bit vectors, with support for 256- and 512-bit vectors and AVX-512 features.</dd></dl>
<dl><dt> <b>VPCLMULQDQ</b> - <a href="/wiki/x86/vpclmulqdq" title="x86/vpclmulqdq"><b>Vector Carry-Less Multiplication of Quadwords</b></a></dt>
<dd> Expands the earlier <a href="/w/index.php?title=x86/pclmulqdq&amp;action=edit&amp;redlink=1" class="new" title="x86/pclmulqdq (page does not exist)">PCLMULQDQ</a> extension, which adds SSE and AVX instructions performing this operation on 128-bit vectors, with support for 256- and 512-bit vectors and AVX-512 features.</dd></dl>
<dl><dt> <b>GFNI</b> - <a href="/wiki/x86/gfni" title="x86/gfni"><b>Galois Field New Instructions</b></a></dt>
<dd> Adds Galois Field transformation instructions.</dd></dl>
<p>Note that,
</p>
<ul><li> Formerly, the term <b>AVX3.1</b> referred to <code>F + CD + ER + PF</code>.</li>
<li> Formerly, the term <b>AVX3.2</b> referred to <code>F + CD + BW + DQ + VL</code>.</li></ul>
<h2><span class="mw-headline" id="Registers">Registers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=2" title="Edit section: Registers">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>AVX-512 defines 32 512-bit vector registers ZMM0 ... ZMM31. They are shared by integer and floating point vector instructions and can contain 64 bytes, or 32 16-bit words, or 16 doublewords, or 8 quadwords, or 32 half precision, 16 single precision, 16 <a href="/wiki/bfloat16" class="mw-redirect" title="bfloat16">BFloat16</a>, or 8 double precision IEEE 754 floating point values. If the integer values are interpreted as signed or unsigned depends on the instruction. As x86 is a little-endian architecture elements are numbered from zero beginning at the least significant byte of the register, and vectors are stored in memory LSB to MSB regardless of vector size and element type. Some instructions group elements in lanes. A pair of single precision values in the second 64-bit lane for instance refers to bits 64 ... 95 and 96 ... 127 of the register, again counting from the least significant bit.
</p><p>The earlier AVX extension, which supports only 128- and 256-bit vectors, similarly defines 16 256-bit vector registers YMM0 ... YMM15. These are aliased to the lower half of the registers ZMM0 ... ZMM15. The still earlier SSE extension defines 16 128-bit vector registers XMM0 ... XMM15. These are aliased to the lowest quarter of the registers ZMM0 ... ZMM15. That means AVX-512 instructions can access the results of AVX and SSE instructions and to some degree vice versa. MMX instructions, the oldest vector instructions on x86 processors, use different registers. The full set of registers is only available in x86-64 mode. In other modes SSE, AVX, and AVX-512 instructions can only access the first eight registers.
</p><p>AVX-512 instructions generally operate on 512-bit vectors. Often variants operating on 128- and 256-bit vectors are also available, and sometimes only a 128-bit variant. Shorter vectors are stored towards the LSB of the vector registers. Accordingly in assembler code the vector size is implied by register names XMM, YMM, and ZMM. AVX-512 instructions can of course access 32 of all these registers.
</p><p>Use of 128- and 256-bit vectors can be beneficial to reduce memory traffic and achieve performance gains on implementations which complete 512-bit instructions as two or even four internal operations. This also explains why many horizontal operations are confined to 128-bit lanes. Motivations of such implementations can be a reduction of execution resources due to die size or complexity constraints, or performance optimizations where execution resources are dynamically disabled if power or thermal limits are reached instead of downclocking the CPU core which also affects uncritical instructions. If AVX-512 features are not needed shorter equivalent AVX instructions may also improve instruction cache utilization.
</p>
<h2><span class="mw-headline" id="Write_masking">Write masking</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=3" title="Edit section: Write masking">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Most AVX-512 instructions support write masking. That means they can write individual elements in the destination vector unconditionally, leave them unchanged, or zero them if the corresponding bit in a mask register supplied as an additional source operand is zero. The masking mode is encoded in the instruction opcode. AVX-512 defines 8 64-bit mask registers K0 ... K7. Masks can vary in width from 1 to 64 bits depending on the instruction (e.g. some operating on a single vector element) and the number of elements in the vector. They are likewise stored towards the LSB of the mask registers.
</p><p>One application of write masking are predicated instructions. In vectorized code conditional operations on individual elements are not possible. A solution is to form predicates by comparing elements and execute the conditional operations regardless of outcome, but skip writes for results where the predicate is negative. This was already possible with MMX compare and bitwise logical instructions. Write masking improves the code density by blending results as a side effect. Another application are operations on arrays which do not match the vector sizes supported by AVX-512 or which are inconveniently aligned.
</p>
<h2><span class="mw-headline" id="Memory_fault_suppression">Memory fault suppression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=4" title="Edit section: Memory fault suppression">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>AVX-512 supports memory fault suppression. A memory fault occurs for instance if a vector loaded from memory crosses a page boundary and one of the pages is unreadable because no physical memory was allocated to that virtual address. Programmers and compilers can avoid this by aligning vectors. A vectorized function served with pointers as parameters has to prepare code handling these edge cases at runtime. With memory fault suppression it can just mask out bytes it was not supposed to load from or store in memory and no exceptions will be generated for those bytes.
</p>
<h2><span class="mw-headline" id="Integer_instructions">Integer instructions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=5" title="Edit section: Integer instructions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Common aspects:
</p>
<ul><li> Parallel operations are performed on the corresponding elements of the destination and source operands.</li>
<li> A &#34;word&#34; is 16 bits wide, a &#34;doubleword&#34; 32 bits, a &#34;quadword&#34; 64 bits.</li>
<li> Signed saturation: min(max(-2<sup>W-1</sup>, x), 2<sup>W-1</sup> - 1),</li>
<li> Unsigned saturation: min(max(0, x), 2<sup>W</sup> - 1), where W is the destination data type width in bits.</li>
<li> Except as noted the destination operand and the first of two source operands is a vector register.</li>
<li> If the destination is a vector register and the vector size is less than 512 bits AVX and AVX-512 instructions zero the unused higher bits to avoid a dependency on earlier instructions writing those bits. If the destination is a mask register unused higher mask bits due to the vector and element size are cleared.</li>
<li> Except as noted the second or only source operand can be
<ul><li> a vector register,</li>
<li> a vector in memory,</li>
<li> or a single element in memory broadcast to all elements in the vector. The broadcast option is limited to AVX-512 instructions operating on doublewords or quadwords.</li></ul></li>
<li> Some instructions use an immediate value as an additional operand, a byte which is part of the opcode.</li></ul>
<p>The table below lists all AVX-512 instructions operating on integer values. The columns on the right show the x86 extension which introduced the instruction, broken down by instruction encoding and supported vector size in bits. For brevity mnemonics are abbreviated: &#34;(V)PMULLW&#34; means PMULLW (MMX/SSE variant) and VPMULLW (AVX/AVX-512). &#34;P(MIN/MAX)(SD/UD)&#34; means PMINSD, PMINUD, PMAXSD, and PMAXUD, instructions computing the minimum or maximum of signed or unsigned doublewords.
</p>
<table class="wikitable">
<tbody><tr>
<th style="width:100%" rowspan="2"> Instruction
</th>
<th> MMX </th>
<th> SSE </th>
<th colspan="2"> AVX </th>
<th colspan="3"> AVX-512
</th></tr>
<tr>
<th> 64 </th>
<th> 128 </th>
<th>  128 </th>
<th> 256  </th>
<th>  128 </th>
<th> 256 </th>
<th> 512
</th></tr>
<tr>
<td> <code>(V)P(ADD/SUB)(/S/US)(B/W)</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code><span id=".28V.29PADD.28D.2FQ.29">(V)PADD(D/Q)</span><span id="VPADDD"></span></code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)PSUB(D/Q)</code>
</td>
<td> SSE2 </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel addition or subtraction (source1 - source2) of bytes, words, doublewords, or quadwords. The result is truncated (), or stored with signed (S) or unsigned saturation (US).
</td></tr>
<tr>
<td> <code>(V)P(MIN/MAX)(SB/UW)</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)P(MIN/MAX)(UB/SW)</code>
</td>
<td> SSE </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)P(MIN/MAX)(SD/UD)</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)P(MIN/MAX)(SQ/UQ)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel minimum or maximum of signed or unsigned bytes, words, doublewords, or quadwords.
</td></tr>
<tr>
<td> <code>(V)PABS(B/W)</code>
</td>
<td> SSSE3 </td>
<td> SSSE3 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PABSD</code>
</td>
<td> SSSE3 </td>
<td> SSSE3 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VPABSQ</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel absolute value of signed bytes, words, doublewords, or quadwords.
</td></tr>
<tr>
<td> <code>(V)PMULLW</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PMULLD</code>, <code>(V)PMULDQ</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)PMULLQ</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td colspan="8"> Parallel multiplication of unsigned words (<code>PMULLW</code>), signed doublewords (<code>PMULDQ</code>), unsigned doublewords (<code>PMULLD</code>), or unsigned quadwords (<code>PMULLQ</code>). The instructions store the lower half of the product in the corresponding words, doublewords, or quadwords of the destination vector.
</td></tr>
<tr>
<td> <code>(V)PMULHW</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PMULHUW</code>
</td>
<td> SSE </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PMULHRSW</code>
</td>
<td> SSSE3 </td>
<td> SSSE3 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> Parallel multiplication of signed words (<code>PMULHW</code>, <code>PMULHRSW</code>) or unsigned words (<code>PMULHUW</code>). The instructions store the upper half of the 32-bit product in the corresponding words of the destination vector. The <code>PMULHRSW</code> instruction rounds the result:
<p>dest = (source1 * source2 + 2<sup>15</sup>) &gt;&gt; 16
</p>
</td></tr>
<tr>
<td> <code>(V)PMULUDQ</code>
</td>
<td> SSE2 </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel multiplication of unsigned doublewords. The instruction reads only the doublewords in the lower half of each 64-bit lane of the source operands and stores the 64-bit quadword product in the same lane of the destination vector.
</td></tr>
<tr>
<td> <code><span id=".28V.29PMADDWD">(V)PMADDWD</span><span id="VPMADDWD"></span></code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> Multiplies the corresponding signed words of the source operands, adds the 32-bit products from the even and odd lanes, and stores the results in the doublewords of the destination vector. The results overflow (wrap around to -2<sup>31</sup>) if all four inputs are -32768. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)PMADDUBSW</code>
</td>
<td> - </td>
<td> SSSE3 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> Multiplies the <i>unsigned</i> bytes in the first source operand with the corresponding <i>signed</i> bytes in the second source operand, adds the 16-bit products from the even and odd lanes, and stores the results with signed saturation in the 16-bit words of the destination vector.
</td></tr>
<tr>
<td> <code>VPMADD52(L/H)UQ</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX-IFMA </td>
<td> AVX-IFMA </td>
<td> IFMA+VL </td>
<td> IFMA+VL </td>
<td> IFMA
</td></tr>
<tr>
<td colspan="8"> Parallel multiply-accumulate. The instructions multiply the 52 least significant bits in corresponding unsigned quadwords of the source operands, then add the lower (L) or upper (H) half of the 104-bit product, zero-extended from 52 to 64 bits, to the corresponding quadword of the destination vector.
</td></tr>
<tr>
<td> <code>VP4DPWSSD(/S)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> 4VNNIW
</td></tr>
<tr>
<td colspan="8">
<p>Dot product of signed 16-bit words, accumulated in doublewords, four iterations.
</p><p>These instructions use two 512-bit vector operands. The first one is a vector register, the second one is obtained by reading a 128-bit vector from memory and broadcasting it to the four 128-bit lanes of a 512-bit vector. The instructions multiply the 32 corresponding signed words in the source operands, then add the signed 32-bit products from the even lanes, odd lanes, and the 16 signed doublewords in the 512-bit destination vector register and store the sums in the destination. Finally the instructions increment the number of the source register by one modulo four, and repeat these operations three more times, reading four vector registers total in a 4-aligned block, e.g. ZMM12 ... ZMM15. Exceptions can occur in each iteration. Write masking is supported.
</p><p><code>VP4DPWSSD</code> can be replaced by 16 <code><a href="/wiki/x86/avx-512#VPDPWSSD" title="x86/avx-512">VPDPWSSD</a></code> instructions (from the later <a href="/wiki/x86/avx512_vnni" title="x86/avx512 vnni">AVX512_VNNI</a> extension) working on 128-bit vectors, or four 512-bit instructions and a memory load with broadcast.
</p><p><code>VP4DPWSSDS</code> performs the same operations except the 33-bit intermediate sum is stored in the destination with signed saturation:
</p><p>dest = min(max(-2<sup>31</sup>, even + odd + dest), 2<sup>31</sup> - 1)
</p><p>Its VNNI equivalent is <code><a href="/wiki/x86/avx-512#VPDPWSSD" title="x86/avx-512">VPDPWSSDS</a></code>.
</p>
</td></tr>
<tr>
<td> <code>VPDPBUSD(/S)</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX-VNNI </td>
<td> AVX-VNNI </td>
<td> VNNI+VL </td>
<td> VNNI+VL </td>
<td> VNNI
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code><span id="VPDPWSSD">VPDPWSSD</span>(/S)</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX-VNNI </td>
<td> AVX-VNNI </td>
<td> VNNI+VL </td>
<td> VNNI+VL </td>
<td> VNNI
</td></tr>
<tr>
<td colspan="8"> Dot product of signed words, accumulated in doublewords. The instructions multiply the corresponding signed words of the source operands, add the signed 32-bit products from the even lanes, odd lanes, and the signed doublewords of the destination vector and store the sums in the destination. <code>VPDPWSSDS</code> performs the same operation except the 33-bit intermediate sum is stored with signed saturation:
<p>dest = min(max(-2<sup>31</sup>, even + odd + dest), 2<sup>31</sup> - 1)
</p><p><code>VPDPWSSD</code> fuses two older instructions <code><a href="#VPMADDWD">VPMADDWD</a></code> which computes the products and even/odd sums, and <code><a href="#VPADDD">VPADDD</a></code> to accumulate the results. <code>VPDPWSSDS</code> cannot be easily replaced because <code>VPMADDWD</code> overflows if all four inputs are equal to -32768 and there is no instruction to add doublewords with saturation.
</p>
</td></tr>
<tr>
<td> <code>(V)PCMP(EQ/GT)(B/W)</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PCMP(EQ/GT)D</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)PCMPEQQ</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)PCMPGTQ</code>
</td>
<td> - </td>
<td> SSE4_2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel compare with predicate equal or greater-than of the signed bytes, words, doublewords, or quadwords in the first and second source operand. The MMX, SSE, and AVX versions store the result, -1 = true or 0 = false, in the corresponding elements of the destination, a vector register. These can be used as masks in bitwise logical operations to emulate predicated vector instructions. The AVX-512 versions set the corresponding bits in the destination mask register to 1 = true or 0 = false.
</td></tr>
<tr>
<td> <code>VCMP(B/UB/W/UW)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VCMP(D/UD/Q/UQ)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel compare operation of the signed or unsigned bytes, words, doublewords, or quadwords in the first and second source operand. One of 8 operations (EQ, LT, LE, F, NEQ, NLT, NLE, T) is selected by an immediate byte. The instructions set the corresponding bits in the destination mask register to 1 = true or 0 = false. The instructions support write masking which performs a bitwise &#39;and&#39; on the destination using a second mask register.
</td></tr>
<tr>
<td> <code>VPTESTM(B/W)</code>, <code>VPTESTNM(B/W)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPTESTM(D/Q)</code>, <code>VPTESTNM(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> These instructions perform a parallel bitwise &#39;and&#39; (TESTM) or &#39;not and&#39; (TESTNM), that is (not source1) and source2, on the bytes, words, doublewords, or quadwords of the source operands, then set the bits in the destination mask register, copying the most significant bit of the corresponding results.
</td></tr>
<tr>
<td> <code>(V)P(AND/ANDN/OR/XOR)(/D/Q)</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel bitwise logical operations. The <code>ANDN</code> operation is (not source1) and source2. The AVX-512 versions operate on doublewords or quadwords, the distinction is necessary because these instructions support write masking which observes the number of elements in the vector.
</td></tr>
<tr>
<td> <code>VPTERNLOG(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel bitwise ternary logical operations on doublewords or quadwords. These instructions concatenate the corresponding bits of the destination, first, and second source operand into a 3-bit index which selects a bit from an 8-bit lookup table provided by an immediate byte, and store it in the corresponding bit of the destination. In other words they can perform any bitwise boolean operation with up to three inputs. The data type distinction is necessary because these instructions support write masking which observes the number of elements in the vector.
</td></tr>
<tr>
<td> <code>VPOPCNT(B/W)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BITALG+VL </td>
<td> BITALG+VL </td>
<td> BITALG
</td></tr>
<tr>
<td> <code>VPOPCNT(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VPOPC+VL </td>
<td> VPOPC+VL </td>
<td> VPOPC
</td></tr>
<tr>
<td colspan="8"> Parallel count of the number of set bits in bytes, words, doublewords, or quadwords.
</td></tr>
<tr>
<td> <code>VPLZCNT(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> CD+VL </td>
<td> CD+VL </td>
<td> CD
</td></tr>
<tr>
<td colspan="8"> Parallel count of the number of leading (most significant) zero bits in doublewords or quadwords.
</td></tr>
<tr>
<td> <code>(V)PS(LL/RA/RL)W</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PS(LL/RA/RL)(D/Q)</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel bitwise left shift (PSLL) or logical (unsigned) right shift (PSRL) or arithmetic (signed) right shift (PSRA) of the words, doublewords, or quadwords in the first or only source operand. The amount can be a constant provided by an immediate byte, or a single value provided by a second source operand, specifically the lowest quadword of a vector register or a 128-bit vector in memory. If the shift amount is greater than or equal to the element size in bits the destination element is zeroed (PSLL, PSRL) or set to -1 or 0 (PSRA). Broadcasting is supported by the constant amount AVX-512 instruction variants operating on doublewords or quadwords.
</td></tr>
<tr>
<td> <code>VPS(LL/RA/RL)VW</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPS(LL/RL)V(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VPSRAVD</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VPSRAVQ</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel bitwise left shift (VPSLL) or logical (unsigned) right shift (VPSRL) or arithmetic (signed) right shift (VPSRA) of the words, doublewords, or quadwords in the first source operand by a per-element variable amount taken from the corresponding element of the second source operand. If the shift amount is greater than or equal to the element size in bits the destination element is zeroed (VPSLL, VPSRL) or set to -1 or 0 (VPSRA).
</td></tr>
<tr>
<td> <code>VPRO(L/R)(/V)(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel bitwise rotate left or right of the doublewords or quadwords in the first or only source operand by a constant () or per-element variable number of bits (V) modulo element width in bits. The instructions take a constant amount from an immediate byte, a variable amount from the corresponding element of a second source operand.
</td></tr>
<tr>
<td> <code>VPSH(L/R)D(W/D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VBMI2+VL </td>
<td> VBMI2+VL </td>
<td> VBMI2
</td></tr>
<tr>
<td colspan="8"> Parallel bitwise funnel shift left or right by a constant amount. The instructions concatenate each word, doubleword, or quadword of the first and second source operand, perform a bitwise logical left or right shift by a constant amount modulo element width in bits taken from an immediate byte, and store the upper (L) or lower (R) half of the result in the corresponding elements of the destination vector.
</td></tr>
<tr>
<td> <code>VPSH(L/R)DV(W/D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VBMI2+VL </td>
<td> VBMI2+VL </td>
<td> VBMI2
</td></tr>
<tr>
<td colspan="8"> Parallel bitwise funnel shift left or right by a per-element variable amount. The instructions concatenate each word, doubleword, or quadword of the <i>destination and first source operand</i>, perform a bitwise logical left or right shift by a variable amount modulo element width in bits taken from the corresponding element of the second source operand, and store the upper (L) or lower (R) half of the result in the corresponding elements of the destination vector.&gt;
</td></tr>
<tr>
<td> <code>VPMULTISHIFTQB</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VBMI+VL </td>
<td> VBMI+VL </td>
<td> VBMI
</td></tr>
<tr>
<td colspan="8">
<p>Copies 8 consecutive bits from the second source operand into each byte of the destination vector using bit indices. For each destination byte the instruction obtains an index from the corresponding byte of the first source operand. The operation is confined to 64-bit quadwords so the indices can only address bits in the same 64-bit lane as the index and destination byte. The instruction increments the index for each bit modulo 64. In other words the operation for each destination byte is:
</p><p>dest.byte[i] = bitwise_rotate_right(source2.quadword[i / 8], source1.byte[i] and 63) and 255
</p><p>The destination and first source operand is a vector register. The second source operand can be a vector register, a vector in memory, or one quadword broadcast to all 64-bit lanes of the vector. Write masking is supported with quadword granularity.
</p>
</td></tr>
<tr>
<td> <code>(V)PS(LL/RL)DQ</code>
</td>
<td> - </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> Parallel <i>bytewise</i> shift left or right of quadwords by a constant amount, shifting in zero bytes. The amount is taken from an immediate byte. If greater than 15 the instructions zero the destination element. Broadcasting and write masking is not supported.
</td></tr>
<tr>
<td> <code>(V)PALIGNR</code>
</td>
<td> SSSE3 </td>
<td> SSSE3 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> Parallel <i>bytewise</i> funnel shift right by a constant amount, shifting in zero bytes. The instruction concatenates the data in corresponding 128-bit lanes of the first and second source operand, shifts the 256-bit intermediate values right by a constant amount times 8 and stores the lower half of the results in the corresponding 128-bit lanes of the destination. The amount is taken from an immediate byte. Broadcasting is not supported. Write masking is supported with byte granularity.
</td></tr>
<tr>
<td> <code>VALIGN(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Element-wise funnel shift right by a constant amount, shifting in zeroed doublewords or quadwords. The instruction concatenates the first and second source operand, performs a bitwise logical right shift by a constant amount times 32 (<code>VALIGND</code>) or 64 (<code>VALIGNQ</code>), and stores the lower half of the vector in the destination vector register. The amount, modulo number of elements in the destination vector, is taken from an immediate byte.
</td></tr>
<tr>
<td> <code>(V)AESDEC</code>, <code>(V)AESDECLAST</code>,<br/> <code>(V)AESENC</code>, <code>(V)AESENCLAST</code>
</td>
<td> - </td>
<td> AESNI </td>
<td> AESNI+AVX </td>
<td> VAES </td>
<td> VAES+VL </td>
<td> VAES+VL </td>
<td> VAES+F
</td></tr>
<tr>
<td colspan="8"> Performs one round, or the last round, of an <a href="http://en.wikipedia.org/wiki/Advanced_Encryption_Standard" class="extiw" title="wikipedia:Advanced Encryption Standard">AES</a> decryption or encryption flow. ... Broadcasting and write masking is not supported.
</td></tr>
<tr>
<td> <code>(V)PCLMULQDQ</code>
</td>
<td> - </td>
<td> PCLM </td>
<td> PCLM+AVX </td>
<td> VPCLM </td>
<td> VPCLM+VL </td>
<td> VPCLM+VL </td>
<td> VPCLM+F
</td></tr>
<tr>
<td colspan="8"> Carry-less multiplication of quadwords. ... Broadcasting and write masking is not supported.
</td></tr>
<tr>
<td> <code>GF2P8AFFINEQB</code>
</td>
<td> - </td>
<td> GFNI </td>
<td> GFNI+AVX </td>
<td> GFNI+AVX </td>
<td> GFNI+VL </td>
<td> GFNI+VL </td>
<td> GFNI+F
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code>GF2P8AFFINEINVQB</code>
</td>
<td> - </td>
<td> GFNI </td>
<td> GFNI+AVX </td>
<td> GFNI+AVX </td>
<td> GFNI+VL </td>
<td> GFNI+VL </td>
<td> GFNI+F
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code>GF2P8MULB</code>
</td>
<td> - </td>
<td> GFNI </td>
<td> GFNI+AVX </td>
<td> GFNI+AVX </td>
<td> GFNI+VL </td>
<td> GFNI+VL </td>
<td> GFNI+F
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code>VPAVG(B/W)</code>
</td>
<td> SSE </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel average of unsigned bytes or words with rounding:
<p>dest = (source1 + source2 + 1) &gt;&gt; 1
</p>
</td></tr>
<tr>
<td> <code>(V)PSADBW</code>
</td>
<td> SSE </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> Computes the absolute difference of the corresponding unsigned bytes in the source operands, adds the eight results from each 64-bit lane and stores the sum in the corresponding 64-bit quadword of the destination vector. Write masking is not supported.
</td></tr>
<tr>
<td> <code>VDBPSADBW</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code>VPMOV(B/W)2M</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPMOV(D/Q)2M</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td colspan="8"> These instructions set the bits in a mask register, copying the most significant bit in the corresponding byte, word, doubleword, or quadword of the source vector in a vector register.
</td></tr>
<tr>
<td> <code>VPMOVM2(B/W)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPMOVM2(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td colspan="8"> These instructions set the bits in each byte, word, doubleword, or quadword of the destination vector in a vector register to all ones or zeros, copying the corresponding bit in a mask register.
</td></tr>
<tr>
<td> <code>VPMOV(/S/US)WB</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPMOV(/S/US)(DB/DW/QB/QW/QD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel down conversion of words, doublewords, or quadwords to bytes, words, or doublewords. The instructions truncate () the input or convert with signed (S) or unsigned saturation (US). The destination operand is a vector register or vector in memory. In the former case the instructions zero unused higher elements. The source operand is a vector register.
</td></tr>
<tr>
<td> <code>(V)MOV(SX/ZX)BW</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)MOV(SX/ZX)(BD/BQ/WD/WQ/DQ)</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel sign or zero extend of bytes, words, or doublewords to words, doublewords, or quadwords. The BW, WD, and DQ instruction variants read only the lower half of the source operand, the BD, WQ variants the lowest quarter, and the BQ variant the lowest one-eighth. The source operand can be a vector register or a vector in memory of the size above. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)MOVDQU</code>, <code>(V)MOVDQA</code>
</td>
<td> - </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> - </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VMOVDQU(8/16)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VMOVDQU(32/64)</code>, <code>VMOVDQA(32/64)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> These instructions copy a vector of 8-bit bytes, 16-bit words, 32-bit doublewords, or 64-bit quadwords between vector registers, or from a vector register to memory or vice versa. The data type distinction is necessary because the AVX-512 versions of these instructions support write masking which observes the number of elements in the vector. For the <code>MOVDQA</code> (&#34;move aligned&#34;) versions the memory address must be a multiple of the vector size in bytes or an exception is generated. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)MOVNTDQA</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Loads a vector from memory into a vector register with a non-temporal hint i.e. it is not beneficial to load the data into the cache hierarchy. The memory address must be a multiple of the vector size in bytes or an exception is generated. Broadcasting and write masking is not supported.
</td></tr>
<tr>
<td> <code>(V)MOVNTDQ</code>
</td>
<td> - </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Stores a vector from a vector register in memory with non-temporal hint i.e. it is not beneficial to perform a write-allocate and/or insert the data in the cache hierarchy. Write masking is not supported.
</td></tr>
<tr>
<td> <code>(V)MOV(D/Q)</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> Copies a doubleword or quadword, the lowest element in a vector register, to a general purpose register or vice versa. If the destination is a vector register the instructions zero the higher elements of the vector. If the element is a doubleword and the destination a 64-bit GPR they zero the upper half. Write masking is not supported.
</td></tr>
<tr>
<td> <code>VMOVW</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> Copies a 16-bit word, the lowest element in a vector register, to a general purpose register or vice versa. Unused higher bits in the destination register are zeroed. Write masking is not supported.
</td></tr>
<tr>
<td> <code>VPSCATTER(D/Q)(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code>VPGATHER(D/Q)(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code>(V)PACKSSWB</code>, <code>(V)PACKSSDW</code>, <code>(V)PACKUSWB</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PACKUSDW</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> These instruction pack the signed words (WB) or doublewords (DW) in the source operands into the bytes or words, respectively, of the destination vector with signed (SS) or unsigned saturation (US). They interleave the results, packing data from the first source operand into the even 64-bit lanes of the destination, data from the second source operand into the odd lanes. Broadcasting is not supported by the WB variants.
</td></tr>
<tr>
<td> <code>(V)PUNPCK(L/H)(BW/WD)</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>(V)PUNPCK(L/H)DQ</code>
</td>
<td> MMX </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)PUNPCK(L/H)QDQ</code>
</td>
<td> - </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> These instructions interleave the bytes, words, doublewords, or quadwords of the first and second source operand. In order to fit the data into the destination vector <code>PUNPCKL</code> reads only the elements in the even 64-bit lanes, <code>UNPCKH</code> only the odd 64-bit lanes of the source operands. Broadcasting is not supported by the BW and WD variants.
</td></tr>
<tr>
<td> <code>VPEXTRB</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> - </td>
<td> BW </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VPEXTRW</code>
</td>
<td> SSE </td>
<td> SSE2/SSE4_1 </td>
<td> AVX </td>
<td> - </td>
<td> BW </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VPEXTR(D/Q)</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> - </td>
<td> DQ </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> These instructions extract a byte, word, doubleword, or quadword using a constant index to select an element from the lowest 128-bit lane of a source vector register and store it in a general purpose register or in memory. A memory destination is not supported by the MMX version of <code>VPEXTRW</code> and by the SSE version introduced by the <a href="/w/index.php?title=x86/sse2&amp;action=edit&amp;redlink=1" class="new" title="x86/sse2 (page does not exist)">SSE2</a> extension. The index is provided by an immediate byte. If the destination register is wider than the element the instructions zero the unused higher bits.
</td></tr>
<tr>
<td> <code>VEXTRACTI32X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VEXTRACTI32X8</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VEXTRACTI64X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VEXTRACTI64X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F
</td></tr>
<tr>
<td> <code>VEXTRACTI128</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> AVX </td>
<td> - </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> These instructions extract four (I32X4) or eight (I32X8) doublewords, or two (I64X2) or four (I64X4) quadwords, or one block of 128 bits (I128), from a lane of that width (e.g. 128 bits for I32X4) of the source operand selected by a constant index and store the data in memory, or in the lowest lane of a vector register. Higher lanes of the destination register are zeroed. The index is provided by an immediate byte. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>VPINSRB</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> - </td>
<td> BW </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VPINSRW</code>
</td>
<td> SSE </td>
<td> SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> BW </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VPINSR(D/Q)</code>
</td>
<td> - </td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> - </td>
<td> DQ </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> Inserts a byte, word, doubleword, or quadword taken from the lowest bits of a general purpose register or from memory, into the lowest 128-bit lane of the destination vector register using a constant index to select the element. The index is provided by an immediate byte. Write masking is not supported.
</td></tr>
<tr>
<td> <code>VINSERTI32X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VINSERTI32X8</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VINSERTI64X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VINSERTI64X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F
</td></tr>
<tr>
<td> <code>VINSERTI128</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> - </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> These instructions insert four (I32X4) or eight (I32X8) doublewords, or two (I64X2) or four (I64X4) quadwords, or one block of 128 bits ($128), in a lane of that width (e.g. 128 bits for I32X4) of the destination vector selected by a constant index provided by an immediate byte. They load this data from memory, or the lowest lane of a vector register specified by the second source operand, and data for the remaining lanes of the destination vector from the corresponding lanes of the first source operand, a vector register. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)PSHUFB</code>
</td>
<td> SSSE3 </td>
<td> SSSE3 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> Shuffles the bytes of the first source operand using variable indices. For each byte of the destination vector the instruction obtains a source index modulo 16 from the corresponding byte of the second source operand. If the most significant bit of the index byte is set the instruction zeros the destination byte instead. The indices can only address a source byte in the same 128-bit lane as the destination byte.
</td></tr>
<tr>
<td> <code>(V)PSHUF(L/H)W</code>
</td>
<td> - </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td colspan="8"> These instructions shuffle the words of the source operand using constant indices. For each element of the destination vector, a 2-bit index selects an element in the same 64-bit lane of the source operand. For each 64-bit lane the same four indices are taken from an immediate byte. The <code>PSHUFLW</code> instruction writes only the even 64-bit lanes of the destination vector and leaves the remaining lanes unchanged, <code>PSHUFHW</code> writes the odd lanes.
</td></tr>
<tr>
<td> <code>(V)PSHUFD</code>
</td>
<td> - </td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Shuffles the doublewords of the source operand using constant indices. For each element of the destination vector, a 2-bit index selects an element in the same 128-bit lane of the source operand. For each 128-bit lane the same four indices are taken from an immediate byte.
</td></tr>
<tr>
<td> <code>VSHUFI32X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VSHUFI64X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Shuffles a 128-bit wide group of four doublewords or two quadwords of the source operands using constant indices. For each 128-bit destination lane an index selects one 128-bit lane of the source operands. The indices for even destination lanes can only address lanes in the first source operand, those for odd destination lanes only lanes in the second source operand. Instruction variants operating on 256-bit vectors use two 1-bit indices, those operating on 512-bit vectors four 2-bit indices, always taken from an immediate byte.
</td></tr>
<tr>
<td> <code>VPSHUFBITQMB</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BITALG+VL </td>
<td> BITALG+VL </td>
<td> BITALG
</td></tr>
<tr>
<td colspan="8"> Shuffles the bits in the first source operand, a vector register, using bit indices. For each bit of the 16/32/64-bit mask in a destination mask register, the instruction obtains a source index modulo 64 from the corresponding byte in a second source operand, a 128/256/512-bit vector in a vector register or in memory. The operation is confined to quadwords so the indices can only select a bit from the same 64-bit lane where the index byte resides. For instance bytes 8 ... 15 can address bits 64 ... 127. The instruction supports write masking which means it optionally performs a bitwise &#39;and&#39; on the destination using a second mask register.
</td></tr>
<tr>
<td> <code>VPERMB</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VBMI+VL </td>
<td> VBMI+VL </td>
<td> VBMI
</td></tr>
<tr>
<td> <code>VPERM(W/D)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Permutes the bytes, words, or doublewords of the second source operand using element indices. For each element of the destination vector the instruction obtains a source index, modulo vector size in elements, from the corresponding element of the first source operand.
</td></tr>
<tr>
<td> <code>VPERMQ</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Permutes the quadwords of a source operand within a 256-bit lane using constant or variable source element indices. For each destination element the constant index instruction variant obtains a 2-bit index from an immediate byte, and uses the same four indices in each 256-bit lane. The destination operand is a vector register. The source operand can be a vector register, a vector in memory, or one quadword in memory broadcast to all elements of the vector.
<p>The variable index variant permutes the elements of a <i>second</i> source operand. For each destination element it obtains a 2-bit source index from the corresponding quadword of the first source operand. The destination and first source operand is a vector register. The second source operand can be a vector register, a vector in memory, or one quadword in memory broadcast to all elements of the vector. 
</p>
</td></tr>
<tr>
<td> <code>VPERM(I/T)2B</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VBMI+VL </td>
<td> VBMI+VL </td>
<td> VBMI
</td></tr>
<tr>
<td> <code>VPERM(I/T)2W</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPERM(I/T)2(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> The &#34;I&#34; instruction variant concatenates the second and first source operand and permutes their elements using element indices. For each element of the destination vector it obtains a source index, modulo twice the vector size in elements, from the byte, word, doubleword, or quadword in this lane and overwrites it.<br/>The &#34;T&#34; variant concatenates the second source and destination operand, and obtains the source indices from the first source operand. In other words the instructions perform the same operation, one overwriting the indices, the other one half of the data table. The destination and first source operand is a vector register. The second source operand can be a vector register, a vector in memory, or a single value broadcast to all elements of the vector if the element is 32 or 64 bits wide.
</td></tr>
<tr>
<td> <code>VPCOMPRESS(B/W)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VBMI2+VL </td>
<td> VBMI2+VL </td>
<td> VBMI2
</td></tr>
<tr>
<td> <code>VPCOMPRESS(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> These instructions copy bytes, words, doublewords, or quadwords from a vector register to memory or another vector register. They copy each element in the source vector if the corresponding bit in a mask register is set, and only then increment the memory address or destination register element number for the next store. Remaining elements if the destination is a register are left unchanged or zeroed depending on the instruction variant.
</td></tr>
<tr>
<td> <code>VPEXPAND(B/W)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VBMI2+VL </td>
<td> VBMI2+VL </td>
<td> VBMI2
</td></tr>
<tr>
<td> <code>VPEXPAND(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> These instructions copy bytes, words, doublewords, or quadwords from memory or a vector register to another vector register. They load each element of the destination register, if the corresponding bit in a mask register is set, from the source and only then increment the memory address or source register element number for the next load. Destination elements where the mask bit is cleared are left unchanged or zeroed depending on the instruction variant.
</td></tr>
<tr>
<td> <code><span id="VPBLENDM">VPBLENDM</span>(B/W)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPBLENDM(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Parallel blend of the bytes, words, doublewords, or quadwords in the source operands. For each element in the destination vector the corresponding bit in a mask register selects the element in the first source operand (0) or second source operand (1). If no mask operand is provided the default is all ones. &#34;Zero-masking&#34; variants of the instructions zero the destination elements where the mask bit is 0. In other words these instructions are equivalent to copying the first source operand to the destination, then the second source operand with regular write masking.
</td></tr>
<tr>
<td> <code>VPBROADCAST(B/W)</code> from VR or memory
</td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> AVX2 </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPBROADCAST(B/W)</code> from GPR
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BW+VL </td>
<td> BW+VL </td>
<td> BW
</td></tr>
<tr>
<td> <code>VPBROADCAST(D/Q)</code> from VR or memory
</td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VPBROADCAST(D/Q)</code> from GPR
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VPBROADCASTI32X2</code> from VR or memory
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VPBROADCASTI32X4</code> from VR or memory
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VPBROADCASTI32X8</code> from VR or memory
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VPBROADCASTI64X2</code> from VR or memory
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VPBROADCASTI64X4</code> from VR or memory
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F
</td></tr>
<tr>
<td> <code>VPBROADCASTI128</code> from memory
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> - </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> These instructions broadcast one byte, or one word, or one (D), two (I32X2), four (I32X4), or eight (I32X8) doublewords, or one (Q), two (I64X2), or four (I64X4) quadwords, or one block of 128 bits (I128), from the lowest lane of that width (e.g. 64 bits for I32X2) of a source vector register, or from memory, or from a general purpose register to all lanes of that width in the destination vector. The AVX-512 instructions support write masking with byte, word, doubleword, or quadword granularity.
</td></tr>
<tr>
<td> <code>VPBROADCASTM(B2Q/W2D)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> CD+VL </td>
<td> CD+VL </td>
<td> CD
</td></tr>
<tr>
<td colspan="8"> These instructions broadcast the lowest byte or word in a mask register to all doublewords or quadwords of the destination vector in a vector register. Write masking is not supported.
</td></tr>
<tr>
<td> <code>VP2INTERSECT(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> VP2IN+VL </td>
<td> VP2IN+VL </td>
<td> VP2IN+F
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td> <code>VPCONFLICT(D/Q)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> CD+VL </td>
<td> CD+VL </td>
<td> CD
</td></tr>
<tr>
<td colspan="8"> ...
</td></tr>
<tr>
<td colspan="8"> Total: 310
</td></tr></tbody></table>
<h2><span class="mw-headline" id="Floating_point_instructions">Floating point instructions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=6" title="Edit section: Floating point instructions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Common aspects:
</p>
<ul><li> Parallel operations are performed on the corresponding elements of the destination and source operands.</li>
<li> &#34;Packed&#34; instructions with mnemonics ending in PH/PS/PD write all elements of the destination vector. &#34;Scalar&#34; instructions ending in SH/SS/SD write only the lowest element and leave the higher elements unchanged.</li>
<li> Except as noted the destination operand and the first of two source operands is a vector register.</li>
<li> If the destination is a vector register and the vector size is less than 512 bits AVX and AVX-512 instructions zero the unused higher bits to avoid a dependency on earlier instructions writing those bits.</li>
<li> Except as noted the second or only source operand can be
<ul><li> a vector register,</li>
<li> a vector in memory for &#34;packed&#34; instructions,</li>
<li> a single element in memory for &#34;scalar&#34; instructions,</li>
<li> or a single element in memory broadcast to all elements in the vector for &#34;packed&#34; AVX-512 instructions.</li></ul></li>
<li> Some instructions use an immediate value as an additional operand, a byte which is part of the opcode.</li></ul>
<p>Some floating point instructions which merely copy data or perform bitwise logical operations duplicate the functionality of integer instructions. AVX-512 implementations may actually execute vector integer and floating point instructions in separate execution units. Mixing those instructions is not advisable because results will be transferred automatically but this may incur a delay.
</p><p>The table below lists all AVX-512 instructions operating on floating point values. The columns on the right show the x86 extension which introduced the instruction, broken down by instruction encoding and supported vector size in bits. For brevity &#34;SSE/SSE2&#34; means the single precision variant of the instruction was introduced by the <a href="/w/index.php?title=x86/sse&amp;action=edit&amp;redlink=1" class="new" title="x86/sse (page does not exist)">SSE</a>, the double precision variant by the <a href="/w/index.php?title=x86/sse2&amp;action=edit&amp;redlink=1" class="new" title="x86/sse2 (page does not exist)">SSE2</a> extension. Similarly &#34;F/FP16&#34; means the single and double precision variant was introduced by the AVX512F (Foundation) extension, the half precision variant by the <a href="/w/index.php?title=x86/avx512_fp16&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512 fp16 (page does not exist)">AVX512_FP16</a> extension.
</p>
<table class="wikitable">
<tbody><tr>
<th style="width:100%" rowspan="2"> Instruction
</th>
<th> SSE </th>
<th colspan="2"> AVX </th>
<th colspan="3"> AVX-512
</th></tr>
<tr>
<th> 128 </th>
<th> 128 </th>
<th> 256 </th>
<th> 128 </th>
<th> 256 </th>
<th> 512
</th></tr>
<tr>
<td> <code>(V)(ADD/<span id="DIV">DIV</span>/MAX/MIN/MUL/SUB)(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)(ADD/DIV/MAX/MIN/MUL/SUB)(SS/SD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>V(ADD/DIV/MAX/MIN/MUL/SUB)PH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>V(ADD/DIV/MAX/MIN/MUL/SUB)SH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Parallel addition, division (source1 / source2), maximum, minimum, multiplication, or subtraction (source1 - source2), with desired rounding if applicable, of half, single, or double precision values.
</td></tr>
<tr>
<td> <code>VRANGE(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VRANGE(SD/SS)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8">
<p>These instructions perform a parallel minimum or maximum operation on single or double precision values, either on their original or absolute values. They optionally change the sign of all results to positive or negative, or copy the sign of the corresponding element in the first source operand. The operation is selected by an immediate byte.
</p><p>A saturation operation like min(max(-limit, value), +limit) for instance can be expressed as minimum of absolute values with sign copying.
</p>
</td></tr>
<tr>
<td> <code>VF(/N)(MADD/MSUB)(132/213/231)(PS/PD)</code>,<br/><code>VF(MADDSUB/MSUBADD)(132/213/231)(PS/PD)</code>
</td>
<td> - </td>
<td> FMA </td>
<td> FMA </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VF(/N)(MADD/MSUB)(132/213/231)(SS/SD)</code>
</td>
<td> - </td>
<td> FMA </td>
<td> FMA </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VF(/N)(MADD/MSUB)(132/213/231)PH</code>,<br/><code>VF(MADDSUB/MSUBADD)(132/213/231)PH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>VF(/N)(MADD/MSUB)(132/213/231)SH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Parallel fused multiply-add of half, single, or double precision values. These instructions require three source operands, the first source operand is also the destination operand. The numbers in the mnemonic specify the operand order, e.g. 132 means src1 = src1 * src3 + src2. The operations are:
<table>
<tbody><tr>
<td> VFMADD </td>
<td> d = a * b + c
</td></tr>
<tr>
<td> VFMSUB </td>
<td> d = a * b - c
</td></tr>
<tr>
<td> VFMADDSUB </td>
<td> d[even] = a[even] * b[even] - c[even]<br/> d[odd] = a[odd] * b[odd] + c[odd]
</td></tr>
<tr>
<td> VFMSUBADD </td>
<td> d[even] = a[even] * b[even] + c[even]<br/> d[odd] = a[odd] * b[odd] - c[odd]
</td></tr>
<tr>
<td> VFNMADD </td>
<td> d = - a * b + c
</td></tr>
<tr>
<td> VFNMSUB </td>
<td> d = - a * b - c
</td></tr></tbody></table>
</td></tr>
<tr>
<td> <code>VF(/C)MADDC(PH/SH)</code>,<br/><code>VF(/C)MULC(PH/SH)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td colspan="7"> Parallel complex multiplication of half precision pairs. The instructions multiply corresponding pairs of half precision values in the first and second source operand:
<p><code>VFCMADDC</code>, <code>VFCMULC</code>:<br/>
temp[0] = source1[0] * source2[0] - source1[1] * source2[1]<br/>
temp[1] = source1[1] * source2[0] + source1[0] * source2[1]
</p><p><code>VFMADDC</code>, <code>VFMULC</code>:<br/>
temp[0] = source1[0] * source2[0] + source1[1] * source2[1]<br/>
temp[1] = source1[1] * source2[0] - source1[0] * source2[1]
</p><p>The <code>MUL</code> instructions store the result in the corresponding pair of half precision values of the destination, the <code>MADD</code> instructions add the result to this pair. The &#34;packed&#34; instructions (PH) write all elements of the destination vector. the &#34;scalar&#34; instructions (SH) only the lowest pair and leave the higher elements unchanged. Write masking is supported with 32-bit granularity. 
</p>
</td></tr>
<tr>
<td> <code>V4F(/N)MADD(PS/SS)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> 4FMAPS
</td></tr>
<tr>
<td colspan="7">
<p>Parallel fused multiply-accumulate of single precision values, four iterations.
</p><p>In each iteration the instructions source 16 multiplicands from a 512-bit vector register, and one multiplier from memory which is broadcast to all 16 elements of a second vector. They add the 16 products and the 16 values in the corresponding elements of the 512-bit destination register, round the sums as desired, and store them in the destination. Finally the instructions increment the number of the source register by one modulo four, and the memory address by four bytes. Exceptions can occur in each iteration. Write masking is supported.
</p><p>In total these instructions perform 64 multiply-accumulate operations, reading 64 single precision multiplicands from four source registers in a 4-aligned block, e.g. ZMM12 ... ZMM15, four single precision multipliers consecutive in memory, and accumulate 16 single precision results four times, also rounding four times.
</p><p><code>V4FNMADD</code> performs the same operation as <code>V4FMADD</code> except this instruction also negates the product.
</p><p>The &#34;packed&#34; variants (PS) perform the operations above, the &#34;scalar&#34; variants (SS) yield only a single result in the lowest element of the 128-bit destination vector, leaving the three higher elements unchanged. As usual if the vector size is less than 512 bits the instructions zero the unused higher bits in the destination register to avoid a dependency on earlier instructions writing those bits.
</p><p>In total the &#34;scalar&#34; instructions sequentially perform four multiply-accumulate operations, read a single precision multiplicand from four source registers, four single precision multipliers from memory, and accumulate one single precision result four times in the destination register, also rounding four times.
</p>
</td></tr>
<tr>
<td> <code>VDPBF16PS</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BF16+VL </td>
<td> BF16+VL </td>
<td> BF16
</td></tr>
<tr>
<td colspan="7"> Dot product of <a href="/wiki/bfloat16" class="mw-redirect" title="bfloat16">BFloat16</a> values, accumulated in single precision elements. The instruction multiplies the corresponding BF16 values of the source operands, converted to single precision, then adds the products from the even lanes, odd lanes, and the single precision values in the destination operand and stores the sums in the destination.
</td></tr>
<tr>
<td> <code>V<span id="RCP">RCP</span>14(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VRCP28(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> ER
</td></tr>
<tr>
<td> <code>VRCPPH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>VRCP14(SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VRCP28(SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> ER </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VRCPSH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> Parallel approximate reciprocal of half, single, or double precision values. The maximum relative error is less than 2<sup>-14</sup> or 2<sup>-28</sup> (RCP28), see Intel&#39;s <a rel="nofollow" class="external text" href="https://www.intel.com/content/www/us/en/developer/articles/code-sample/reference-implementations-for-ia-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.html">reference implementation</a> for exact values.
<p>Multiplication by a reciprocal can be faster than the <code><a href="#DIV">DIV</a></code> instruction which computes full precision results. More precise results can be achieved using the <a href="http://en.wikipedia.org/wiki/Division_algorithm#Newton.E2.80.93Raphson_division" class="extiw" title="wikipedia:Division algorithm">Newton-Raphson</a> method. For examples see <sup id="cite_ref-Intel-248966-.2A_1-0" class="reference"><a href="#cite_note-Intel-248966-.2A-1">[1</a>]</sup>. 
</p>
</td></tr>
<tr>
<td> <code>(V)<span id="SQRT">SQRT</span>(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VSQRTPH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>(V)SQRT(SS/SD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VSQRTSH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Parallel square root with desired rounding of half, single, or double precision values.
</td></tr>
<tr>
<td> <code>V<span id="RSQRT">RSQRT</span>14(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VRSQRT28(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> ER
</td></tr>
<tr>
<td> <code>VRSQRTPH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>VRSQRT14(SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VRSQRT28(SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> ER </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VRSQRTSH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> Parallel approximate reciprocal of the square root of half, single, or double precision values. The maximum relative error is less than 2<sup>-14</sup> or 2<sup>-28</sup> (RSQRT28), see Intel&#39;s <a rel="nofollow" class="external text" href="https://www.intel.com/content/www/us/en/developer/articles/code-sample/reference-implementations-for-ia-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.html">reference implementation</a> for exact values.
<p>Multiplication by a reciprocal square root can be faster than the <code><a href="#SQRT">SQRT</a></code> and <code><a href="#DIV">DIV</a></code> instructions which compute full precision results. Also <code>RSQRT</code> and <code><a href="#RCP">RCP</a></code> can be faster than <code>SQRT</code>. More precise reciprocal square roots can be computed using <a href="http://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Iterative_methods_for_reciprocal_square_roots" class="extiw" title="wikipedia:Methods of computing square roots">Newton&#39;s method</a>, square roots by Taylor series expansion, both avoiding divisions. For examples see <sup id="cite_ref-Intel-248966-.2A_1-1" class="reference"><a href="#cite_note-Intel-248966-.2A-1">[1</a>]</sup>. 
</p>
</td></tr>
<tr>
<td> <code>VEXP2(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> ER
</td></tr>
<tr>
<td colspan="7"> Parallel approximation of 2<sup>x</sup> of single or double precision values. The maximum relative error is less than 2<sup>-23</sup>, see Intel&#39;s <a rel="nofollow" class="external text" href="https://www.intel.com/content/www/us/en/developer/articles/code-sample/reference-implementations-for-ia-approximation-instructions-vrcp14-vrsqrt14-vrcp28-vrsqrt28-vexp2.html">reference implementation</a> for exact values.
</td></tr>
<tr>
<td> <code>(V)CMP*(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)CMP*(SS/SD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VCMP*PH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>VCMP*SH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Parallel compare operation of the half, single, or double precision values in the first and second source operand. One of 32 operations (CMPEQ - equal, CMPLT - less than, CMPEQ_UO - equal unordered, ...) is selected by an immediate byte. The results, 1 = true or 0 = false, are stored in the destination.
<p>For AVX-512 versions of the instructions the destination is a mask register with bits corresponding to the source elements. The &#34;scalar&#34; instructions (SH/SS/SD) set only the lowest bit. Unused bits due to the vector and element size are zeroed. The instructions support write masking which performs a bitwise &#39;and&#39; on the destination using a second mask register.
</p><p>For SSE/AVX versions the negated results (-1 or 0) are stored in a vector of doublewords (PS/SS) or quadwords (PD/SD) corresponding to the source elements. These can be used as masks in bitwise logical operations to emulate predicated vector instructions. 
</p>
</td></tr>
<tr>
<td> <code>(V)(/U)COMI(SS/SD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>V(/U)COMISH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Compares the half, single, or double precision values in the lowest element of the first and second source operand and stores the result in the <abbr title="Zero Flag">ZF</abbr> (equal), <abbr title="Carry Flag">CF</abbr> (less than), and <abbr title="Parity Flag">PF</abbr> (unordered) for branch instructions. UCOMI instructions perform an unordered compare and only generate an exception if a source operand is a <a href="http://en.wikipedia.org/wiki/NaN" class="extiw" title="wikipedia:NaN"><abbr title="Signaling Not-a-Number">SNaN</abbr></a>, COMI instructions also for <a href="http://en.wikipedia.org/wiki/NaN" class="extiw" title="wikipedia:NaN"><abbr title="Quiet Not-a-Number">QNaN</abbr>s</a>. Broadcasting and write masking is not supported.
</td></tr>
<tr>
<td> <code>VFPCLASS(PH/PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ/FP16+VL </td>
<td> DQ/FP16+VL </td>
<td> DQ/FP16
</td></tr>
<tr>
<td> <code>VFPCLASS(SH/SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ/FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> These instructions test if the half, single, or double precision values in the source operand belong to certain classes and set the bit corresponding to each element in the destination mask register to 1 = true or 0 = false. The &#34;packed&#34; instructions (PH/PS/PD) operate on all elements, the &#34;scalar&#34; instructions (SH/SS/SD) only on the lowest element and set a single mask bit. Unused higher bits of the 64-bit mask register are cleared. The instructions support write masking which means they optionally perform a bitwise &#39;and&#39; on the destination using a second mask register. The class is selected by an immediate byte and can be: <a href="http://en.wikipedia.org/wiki/NaN" class="extiw" title="wikipedia:NaN"><abbr title="Quiet Not-a-Number">QNaN</abbr></a>, +0, -0, +∞, -∞, denormal, negative, <a href="http://en.wikipedia.org/wiki/NaN" class="extiw" title="wikipedia:NaN"><abbr title="Signaling Not-a-Number">SNaN</abbr></a>, or any combination.
</td></tr>
<tr>
<td> <code>(V)(AND/ANDN/OR/XOR)(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> DQ+VL </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td colspan="7"> Parallel bitwise logical operations on single or double precision values. There are no &#34;scalar&#34; variants operating on a single element. The <code>ANDN</code> operation is (not source1) and source2. The precision distinction is necessary because all these instructions support write masking which observes the number of elements in the vector.
</td></tr>
<tr>
<td> <code>VRNDSCALE(PH/PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16+VL </td>
<td> F/FP16+VL </td>
<td> F/FP16
</td></tr>
<tr>
<td> <code>VRNDSCALE(SH/SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> Parallel rounding to a given number of fractional bits on half, single, or double precision values. The operation is
<p>dest = round(2<sup>M</sup> * source) * 2<sup>-M</sup>
</p><p>with desired rounding mode and M a constant in range 0 ... 15.
</p>
</td></tr>
<tr>
<td> <code>VREDUCE(PH/PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ/FP16+VL </td>
<td> DQ/FP16+VL </td>
<td> DQ/FP16
</td></tr>
<tr>
<td> <code>VREDUCE(SH/SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ/FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8">
<p>Parallel reduce transformation on half, single, or double precision values. The operation is
</p><p>dest = source – round(2<sup>M</sup> * source) * 2<sup>-M</sup>
</p><p>with desired rounding mode and M a constant in range 0 ... 15. These instructions can be used to accelerate transcendental functions.
</p>
</td></tr>
<tr>
<td> <code>VSCALEF(PH/PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16+VL </td>
<td> F/FP16+VL </td>
<td> F/FP16
</td></tr>
<tr>
<td> <code>VSCALEF(SH/SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="8"> Parallel scale operation on half, single, or double precision values. The operation is:
<p>dest = source1 * 2<sup>floor(source2)</sup>
</p>
</td></tr>
<tr>
<td> <code>VGETEXP(PH/PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16+VL </td>
<td> F/FP16+VL </td>
<td> F/FP16
</td></tr>
<tr>
<td> <code>VGETEXP(SH/SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> ...
</td></tr>
<tr>
<td> <code>VGETMANT(PH/PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16+VL </td>
<td> F/FP16+VL </td>
<td> F/FP16
</td></tr>
<tr>
<td> <code>VGETMANT(SH/SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F/FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> ...
</td></tr>
<tr>
<td> <code>VFIXUPIMM(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VFIXUPIMM(SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> ...
</td></tr>
<tr>
<td> <code>(V)CVTPS2PD</code> - <code>(V)CVTPD2PS</code>
</td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)CVT(PS/PD)2DQ</code> - <code>(V)CVTDQ2(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>(V)CVTT(PS/PD)2DQ</code>
</td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VCVT(/T)(PS/PD)2UDQ</code> - <code>VCVTUDQ2(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VCVT(/T)(PS/PD)2(QQ/UQQ)</code> - <code>VCVT(QQ/UQQ)2(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>(V)CVTSD2(SI/SS)</code> - <code>(V)CVT(SI/SS)2SD</code>, <code>(V)CVTTSD2SI</code>
</td>
<td> SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>(V)CVT(/T)SS2SI</code> - <code>(V)CVTSI2SS</code>
</td>
<td> SSE </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VCVT(/T)(SS/SD)2USI</code> - <code>VCVTUSI2(SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VCVTPH2PD</code> - <code>VCVTPD2PH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>VCVTPH2PSX</code> - <code>VCVTPS2PHX</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>VCVTPH2PS</code> - <code>VCVTPS2PH</code>
</td>
<td> - </td>
<td> F16C </td>
<td> F16C </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VCVT(/T)PH2(W/UW/DQ/UDQ/QQ/UQQ)</code> - <code>VCVT(W/UW/DQ/UDQ/QQ/UQQ)2PH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16+VL </td>
<td> FP16+VL </td>
<td> FP16
</td></tr>
<tr>
<td> <code>VCVT(SS/SD)2SH</code> - <code>VCVTSH2(SS/SD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td> <code>VCVT(/T)SH2(SI/USI)</code> - <code>VCVT(SI/USI)2SH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Parallel conversion with desired rounding. Supported data types are
<ul><li> signed and unsigned 16-bit words (W/UW),</li>
<li> signed and unsigned 32-bit doublewords (DQ/UDQ),</li>
<li> signed and unsigned 64-bit quadwords (QQ/UQQ),</li>
<li> signed and unsigned 32/64-bit integers (SI/USI) in a <abbr title="General Purpose Register">GPR</abbr>,</li>
<li> 16-bit half precision (PH/SH),</li>
<li> 32-bit single precision (PS/SS), and</li>
<li> 64-bit double precision (PD/SD) floating point values.</li></ul>
<p>The destination operand is generally a vector register. The &#34;packed&#34; instructions (PH/PS/PD source or destination) write all elements of the destination vector. If the source and destination data types differ in size, instructions with a 16 bit source or 64 bit destination type leave some higher source elements unconverted. Those with a 16 bit destination or 64 bit source type process all source elements and set excess elements in the destination vector to zero. The &#34;scalar&#34; instructions (SH/SS/SD source or destination) write only the lowest element and leave the higher elements unchanged. Instructions with SI/USI destination store the result in a 32- or 64-bit general purpose register instead. All conversion instructions with a vector destination except <code>(V)CVTSI2SS</code> and <code>(V)CVTSI2SD</code> support write masking with the granularity of the destination data type.
</p><p>The source operand can be a vector register, or for &#34;packed&#34; instructions a vector in memory, or one value in memory broadcast to all elements of the source vector, or for &#34;scalar&#34; instructions with SI/USI source a 32- or 64-bit general purpose register. The broadcast option is not available for <code>VCVTPS2PH</code> and <code>VCVTPH2PS</code> instructions. The <code>VCVTPS2PHX</code> and <code>VCVTPH2PSX</code> instructions do support broadcasting.
</p>
</td></tr>
<tr>
<td> <code>VCVT(NE/NE2)PS2BF16</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> BF16+VL </td>
<td> BF16+VL </td>
<td> BF16
</td></tr>
<tr>
<td colspan="7"> Parallel conversion with desired rounding of single precision to <a href="/wiki/bfloat16" class="mw-redirect" title="bfloat16">BFloat16</a> values. The <code>VCVTNEPS2BF16</code> instruction uses one source operand, writes only to the lower half of the destination vector and zeros the remaining elements. The <code>VCVTNE<b>2</b>PS2BF16</code> instruction stores converted elements from the first source operand in the upper half, the second source operand in the lower half of the destination vector.
</td></tr>
<tr>
<td> <code>(V)MOV(A/U)(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Copies a vector of single or double precision values between vector registers or from a vector register to memory or vice versa. The precision distinction is necessary because these instructions support write masking which observes the number of elements in the vector. For the MOVA (&#34;move aligned&#34;) variants the memory address must be a multiple of the vector size in bytes or an exception is generated.
</td></tr>
<tr>
<td> <code>(V)MOVNT(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Stores a vector in memory with non-temporal hint i.e. it is not beneficial to perform a write-allocate and/or insert the data in the cache hierarchy. The source operand is a vector register. Write masking is not supported.
</td></tr>
<tr>
<td> <code>(V)MOV(SS/SD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Copies one single or double precision value between vector registers or from a vector register to memory or vice versa. The instructions read and write the lowest element in a vector. They zero higher elements of the destination vector if the source is memory and leave them unchanged otherwise. Broadcasting is not supported, but write masking is.
</td></tr>
<tr>
<td> <code>VMOVSH</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> FP16 </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Parallel copy of half precision values between vector registers, or from a vector register to memory or vice versa. The reg-reg variant copies the lowest element from a second source operand, the higher elements from the first source operand. The memory load variant writes the lowest element in the destination vector and leaves the higher elements unchanged. The memory store variant stores the lowest element of the source operand in memory.
</td></tr>
<tr>
<td> <code>VGATHER(D/Q)(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> ...
</td></tr>
<tr>
<td> <code>VGATHERPF(0/1)(D/Q)(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> PF </td>
<td> PF </td>
<td> PF
</td></tr>
<tr>
<td colspan="7"> ...
</td></tr>
<tr>
<td> <code>VSCATTER(D/Q)(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> ...
</td></tr>
<tr>
<td> <code>VSCATTERPF(0/1)(D/Q)(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> PF </td>
<td> PF </td>
<td> PF
</td></tr>
<tr>
<td colspan="7"> ...
</td></tr>
<tr>
<td> <code>(V)MOVDDUP</code>
</td>
<td> SSE3 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Copies the double precision values in the even lanes of the source operand to the even and odd lanes of the destination operand. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)MOVS(L/H)DUP</code>
</td>
<td> SSE3 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Copies the single precision values in the even (MOVSL) or odd lanes (MOVSH) of the source operand to the even and odd lanes of the destination operand. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)UNPCK(L/H)(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> These instructions interleave the single or double precision value values of the first and second source operand. In order to fit the data into the destination vector <code>PUNPCKL</code> reads only the elements in the even 64-bit lanes, <code>UNPCKH</code> only the odd 64-bit lanes of the source operands.
</td></tr>
<tr>
<td> <code>(V)MOV(L/H/HL/LH)(PS/PD)</code>
</td>
<td> SSE/SSE2 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> These instructions copy a 64-bit pair of single precision values (PS) or one 64-bit double precision value (PD). If the source operand is a vector register the <code>MOVL</code> and <code>MOVLH</code> instructions copy the lower half, <code>MOVH</code> and <code>MOVHL</code> the upper half of the 128-bit source vector. If the destination operand is a vector register they copy the data to both halves. For <code>MOVLH</code> and <code>MOVHL</code> both operands are vector registers. For <code>MOVL</code> and <code>MOVH</code> the source <i>or</i> destination is memory. Broadcasting and write masking is not supported.
</td></tr>
<tr>
<td> <code>(V)EXTRACTPS</code>
</td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Extracts a single precision value using a constant index to select an element of the source operand and stores it in a general purpose register or in memory. If the destination is a 64-bit register the instruction zeros the upper half.
</td></tr>
<tr>
<td> <code>VEXTRACTF32X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VEXTRACTF32X8</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VEXTRACTF64X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VEXTRACTF64X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F
</td></tr>
<tr>
<td> <code>VEXTRACTF128</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX </td>
<td> - </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> These instructions extract four (F32X4) or eight (F32X8) single precision values, or two (F64X2) or four (F64X4) double precision values, or one block of 128 bits (F128), from a lane of that width (e.g. 128 bits for F32X4) of the source operand selected by a constant index and store the data in memory, or in the lowest lane of a vector register. Higher lanes of the destination register are zeroed. The index is provided by an immediate byte. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)INSERTPS</code>
</td>
<td> SSE4_1 </td>
<td> AVX </td>
<td> - </td>
<td> F </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> Inserts a single precision value using two indices to select an element in the source operand and the destination operand. Additionally zeros the elements in the destination where the corresponding bit in a 4-bit mask is set. The indices and the mask are constants in an immediate byte. Broadcasting and AVX-512 write masking is not supported.
</td></tr>
<tr>
<td> <code>VINSERTF32X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VINSERTF32X8</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VINSERTF64X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VINSERTF64X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F
</td></tr>
<tr>
<td> <code>VINSERTF128</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX </td>
<td> - </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> These instructions insert four (F32X4) or eight (F32X8) single precision values, or two (F64X2) or four (F64X4) double precision values, or one block of 128 bits ($128), in a lane of that width (e.g. 128 bits for F32X4) of the destination vector selected by a constant index provided by an immediate byte. They load this data from memory, or the lowest lane of a vector register specified by the second source operand, and data for the remaining lanes of the destination vector from the corresponding lanes of the first source operand, a vector register. Broadcasting is not supported.
</td></tr>
<tr>
<td> <code>(V)SHUFPS</code>
</td>
<td> SSE </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Shuffles the single precision values of the source operands using constant indices. For each element of the destination vector, a 2-bit index selects an element in the same 128-bit lane of the source operands. The indices for even 64-bit destination lanes can only address elements in the first source operand, those for odd lanes only elements in the second source operand. For each 128-bit lane the same four indices are taken from an immediate byte.
</td></tr>
<tr>
<td> <code>(V)SHUFPD</code>
</td>
<td> SSE2 </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Shuffles the double precision values of the source operands using constant indices. For each element of the destination vector, a 1-bit index selects an element in the same 128-bit lane of the source operands. The indices for even 64-bit destination lanes can only address elements in the first source operand, those for odd lanes only elements in the second source operand. The indices are taken from an immediate byte.
</td></tr>
<tr>
<td> <code>VSHUFF32X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VSHUFF64X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Shuffles a 128-bit wide group of four single precision or two double precision values of the source operands using constant indices. For each 128-bit destination lane an index selects one 128-bit lane of the source operands. The indices for even destination lanes can only address lanes in the first source operand, those for odd destination lanes only lanes in the second source operand. Instruction variants operating on 256-bit vectors use two 1-bit indices, those operating on 512-bit vectors four 2-bit indices, always taken from an immediate byte.
</td></tr>
<tr>
<td> <code>VPERM(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Permutes the single or double precision values of the source operand within a 256-bit lane using constant or variable source element indices. For each destination element the <code>VPERMPD</code> instruction with constant indices obtains a 2-bit index from an immediate byte and uses the same four indices in each 256-bit lane. <code>VPERMPS</code> does not support constant indices.
<p>The variable index variants permute the elements of a <i>second</i> source operand. For each destination element they obtain a 3-bit (PS) or 2-bit (PD) source index from the corresponding doubleword or quadword of the first source operand. 
</p>
</td></tr>
<tr>
<td> <code>VPERM(I/T)2(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> The &#34;I&#34; instruction variant concatenates the second and first source operand and permutes their elements using element indices. For each element of the destination vector it obtains a source index, modulo twice the vector size in elements, from the doubleword or quadword in this lane and overwrites it.<br/>The &#34;T&#34; variant concatenates the second source and destination operand, and obtains the source indices from the first source operand. In other words the instructions perform the same operation, one overwriting the indices, the other one half of the data table. The destination and first source operand is a vector register. The second source operand can be a vector register, a vector in memory, or a single value broadcast to all elements of the vector.
</td></tr>
<tr>
<td> <code>VPERMIL(PS/PD)</code>
</td>
<td> - </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="8"> Permutes the single or double precision values of the first source operand within a 128-bit lane using constant or variable source element indices. For each destination element the <code>VPERMILPD</code> instruction with constant indices obtains a 1-bit index from an immediate byte. The <code>VPERMILPS</code> instruction selects elements with a 2-bit index from an immediate byte and uses the same four indices for each 128-bit lane of the destination. The destination is a vector register. The source can be a vector register or a vector in memory.
<p>For each destination element the variable index variants obtain a source index from the lowest two bits (PS) or the second lowest bit (PD) of the corresponding doubleword or quadword of a second source operand. The first source operand is a vector register. The second source operand can be a vector register, a vector in memory, or one doubleword or quadword in memory broadcast to all elements of the vector. 
</p>
</td></tr>
<tr>
<td> <code>VCOMPRESS(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> These instructions copy single or double precision values from a vector register to memory or another vector register. They copy each element in the source vector if the corresponding bit in a mask register is set, and only then increment the memory address or destination register element number for the next store. Remaining elements if the destination is a register are left unchanged or zeroed depending on the instruction variant.
</td></tr>
<tr>
<td> <code>VEXPAND(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> These instructions copy single or double precision values from memory or a vector register to another vector register. They load each element of the destination register, if the corresponding bit in a mask register is set, from the source and only then increment the memory address or source register element number for the next load. Destination elements where the mask bit is cleared are left unchanged or zeroed depending on the instruction variant.
</td></tr>
<tr>
<td> <code>VBLENDM(PS/PD)</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td colspan="7"> Parallel blend of the single or double precision value in the source operands. For each element in the destination vector the corresponding bit in a mask register selects the element in the first source operand (0) or second source operand (1). If no mask operand is provided the default is all ones. &#34;Zero-masking&#34; variants of the instructions zero the destination elements where the mask bit is 0. In other words these instructions are equivalent to copying the first source operand to the destination, then the second source operand with regular write masking.
</td></tr>
<tr>
<td> <code>VBROADCASTSS</code>, memory source
</td>
<td> - </td>
<td> AVX </td>
<td> AVX </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VBROADCASTSS</code>, register source
</td>
<td> - </td>
<td> AVX2 </td>
<td> AVX2 </td>
<td> F+VL </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VBROADCASTF32X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VBROADCASTF32X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VBROADCASTF32X8</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VBROADCASTSD</code>, memory source
</td>
<td> - </td>
<td> - </td>
<td> AVX </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VBROADCASTSD</code>, register source
</td>
<td> - </td>
<td> - </td>
<td> AVX2 </td>
<td> - </td>
<td> F+VL </td>
<td> F
</td></tr>
<tr>
<td> <code>VBROADCASTF64X2</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> DQ+VL </td>
<td> DQ
</td></tr>
<tr>
<td> <code>VBROADCASTF64X4</code>
</td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> - </td>
<td> F
</td></tr>
<tr>
<td> <code>VBROADCASTF128</code>
</td>
<td> - </td>
<td> - </td>
<td> AVX </td>
<td> - </td>
<td> - </td>
<td> -
</td></tr>
<tr>
<td colspan="7"> These instructions broadcast one (SS), two (F32X2), four (F32X4), or eight (F32X8) single precision values, or one (SD), two (F64X2), or four (F64X4) double precision values, or one block of 128 bits (F128), from the lowest lane of that width (e.g. 64 bits for F32X2) of a source vector register, or from memory to all lanes of that width in the destination vector. The AVX-512 instructions support write masking with single or double precision granularity.
</td></tr>
<tr>
<td colspan="7"> Total: 574
</td></tr></tbody></table>
<h2><span class="mw-headline" id="Mask_register_instructions">Mask register instructions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=7" title="Edit section: Mask register instructions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Except as noted the destination and source operands of all these instructions are mask registers. Byte, word, and doubleword instructions zero-extend the result to 64 bits.
</p>
<table class="wikitable">
<tbody><tr>
<th style="width:100%" rowspan="2"> Instruction
</th>
<th colspan="4"> AVX-512
</th></tr>
<tr>
<th> B </th>
<th> W </th>
<th> D </th>
<th> Q
</th></tr>
<tr>
<td> <code>KADD(B/W/D/Q)</code>
</td>
<td> DQ </td>
<td> DQ </td>
<td> BW </td>
<td> BW
</td></tr>
<tr>
<td colspan="5"> Add two masks.
</td></tr>
<tr>
<td> <code>K(AND/ANDN/NOT/OR/XNOR/XOR)(B/W/D/Q)</code>
</td>
<td> DQ </td>
<td> F </td>
<td> BW </td>
<td> BW
</td></tr>
<tr>
<td colspan="5"> Bitwise logical operations. <code>ANDN</code> is (not source1) and source2, <code>XNOR</code> is not (source1 xor source2).
</td></tr>
<tr>
<td> <code>KTEST(B/W/D/Q)</code>
</td>
<td> DQ </td>
<td> DQ </td>
<td> BW </td>
<td> BW
</td></tr>
<tr>
<td colspan="5"> Performs bitwise operations temp1 = source1 and source2, temp2 = (not source1) and source2, sets the <abbr title="Zero Flag">ZF</abbr> and <abbr title="Carry Flag">CF</abbr> (for branch instructions) to indicate if the respective result is all zeros.
</td></tr>
<tr>
<td> <code>KORTEST(B/W/D/Q)</code>
</td>
<td> DQ </td>
<td> F </td>
<td> BW </td>
<td> BW
</td></tr>
<tr>
<td colspan="5"> Performs bitwise operation temp = source1 or source2, sets <abbr title="Zero Flag">ZF</abbr> to indicate if the result is all zeros, <abbr title="Carry Flag">CF</abbr> if all ones.
</td></tr>
<tr>
<td> <code>KSHIFT(L/R)(B/W/D/Q)</code>
</td>
<td> DQ </td>
<td> F </td>
<td> BW </td>
<td> BW
</td></tr>
<tr>
<td colspan="5"> Bitwise logical shift left/right by a constant.
</td></tr>
<tr>
<td> <code>KMOV(B/W/D/Q)</code>
</td>
<td> DQ </td>
<td> F </td>
<td> BW </td>
<td> BW
</td></tr>
<tr>
<td colspan="5"> Copies a bit mask from a mask register to another mask register, a 32- or 64-bit <abbr title="General Purpose Register">GPR</abbr>, or memory, or from a GPR or memory to a mask register. The mask is zero extended if the destination register is wider.
</td></tr>
<tr>
<td> <code>KUNPCK(BW/WD/DQ)</code>
</td>
<td> - </td>
<td> F </td>
<td> BW </td>
<td> BW
</td></tr>
<tr>
<td colspan="5"> Interleaves the lower halves of the second and first source operand.
</td></tr>
<tr>
<td colspan="5"> Total: 51
</td></tr></tbody></table>
<h2><span class="mw-headline" id="Detection">Detection</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=8" title="Edit section: Detection">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="floatright"><a href="/wiki/File:avx-512_flops.png" class="image"><img alt="avx-512 flops.png" src="/w/images/thumb/5/50/avx-512_flops.png/450px-avx-512_flops.png" width="450" height="253" srcset="/w/images/thumb/5/50/avx-512_flops.png/675px-avx-512_flops.png 1.5x, /w/images/thumb/5/50/avx-512_flops.png/900px-avx-512_flops.png 2x"/></a></div>
<table class="wikitable">
<tbody><tr>
<th colspan="2"> <a href="/w/index.php?title=x86/cpuid&amp;action=edit&amp;redlink=1" class="new" title="x86/cpuid (page does not exist)">CPUID</a> </th>
<th rowspan="2"> Instruction Set
</th></tr>
<tr>
<th> Input </th>
<th> Output
</th></tr>
<tr>
<td rowspan="20"> EAX=07H, ECX=0
</td>
<td> EBX[bit 16] </td>
<td> AVX512F
</td></tr>
<tr>
<td> EBX[bit 17] </td>
<td> AVX512DQ
</td></tr>
<tr>
<td> EBX[bit 21] </td>
<td> <a href="/wiki/x86/avx512_ifma" title="x86/avx512 ifma">AVX512_IFMA</a>
</td></tr>
<tr>
<td> EBX[bit 26] </td>
<td> AVX512PF
</td></tr>
<tr>
<td> EBX[bit 27] </td>
<td> AVX512ER
</td></tr>
<tr>
<td> EBX[bit 28] </td>
<td> AVX512CD
</td></tr>
<tr>
<td> EBX[bit 30] </td>
<td> AVX512BW
</td></tr>
<tr>
<td> EBX[bit 31] </td>
<td> AVX512VL
</td></tr>
<tr>
<td> ECX[bit 01] </td>
<td> <a href="/wiki/x86/avx512_vbmi" title="x86/avx512 vbmi">AVX512_VBMI</a>
</td></tr>
<tr>
<td> ECX[bit 06] </td>
<td> <a href="/wiki/x86/avx512_vbmi2" title="x86/avx512 vbmi2">AVX512_VBMI2</a>
</td></tr>
<tr>
<td> ECX[bit 08] </td>
<td> <a href="/wiki/x86/gfni" title="x86/gfni">GFNI</a>
</td></tr>
<tr>
<td> ECX[bit 09] </td>
<td> <a href="/wiki/x86/vaes" title="x86/vaes">VAES</a>
</td></tr>
<tr>
<td> ECX[bit 10] </td>
<td> <a href="/wiki/x86/vpclmulqdq" title="x86/vpclmulqdq">VPCLMULQDQ</a>
</td></tr>
<tr>
<td> ECX[bit 11] </td>
<td> <a href="/wiki/x86/avx512_vnni" title="x86/avx512 vnni">AVX512_VNNI</a>
</td></tr>
<tr>
<td> ECX[bit 12] </td>
<td> <a href="/wiki/x86/avx512_bitalg" title="x86/avx512 bitalg">AVX512_BITALG</a>
</td></tr>
<tr>
<td> ECX[bit 14] </td>
<td> <a href="/wiki/x86/avx512_vpopcntdq" class="mw-redirect" title="x86/avx512 vpopcntdq">AVX512_VPOPCNTDQ</a>
</td></tr>
<tr>
<td> EDX[bit 02] </td>
<td> <a href="/wiki/x86/avx512_4vnniw" title="x86/avx512 4vnniw">AVX512_4VNNIW</a>
</td></tr>
<tr>
<td> EDX[bit 03] </td>
<td> <a href="/wiki/x86/avx512_4fmaps" title="x86/avx512 4fmaps">AVX512_4FMAPS</a>
</td></tr>
<tr>
<td> EDX[bit 08] </td>
<td> <a href="/w/index.php?title=x86/avx512_vp2intersect&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512 vp2intersect (page does not exist)">AVX512_VP2INTERSECT</a>
</td></tr>
<tr>
<td> EDX[bit 23] </td>
<td> <a href="/w/index.php?title=x86/avx512_fp16&amp;action=edit&amp;redlink=1" class="new" title="x86/avx512 fp16 (page does not exist)">AVX512_FP16</a>
</td></tr>
<tr>
<td rowspan="1"> EAX=07H, ECX=1
</td>
<td> EAX[bit 05] </td>
<td> <a href="/wiki/x86/avx512_bf16" title="x86/avx512 bf16">AVX512_BF16</a>
</td></tr>
</tbody></table>
<h2><span class="mw-headline" id="Implementation">Implementation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=9" title="Edit section: Implementation">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="wikitable">
<tbody><tr>
<th rowspan="2"> Designer </th>
<th rowspan="2"> Microarchitecture </th>
<th rowspan="2"> Year </th>
<th colspan="19"> Support Level
</th></tr>
<tr>
<th> <span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">F</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">CD</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">ER</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">PF</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">BW</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">DQ</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">VL</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">FP16</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">IFMA</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">VBMI</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">VBMI2</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">BITALG</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">VPOPCNTDQ</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">VP2INTERSECT</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">4VNNIW</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">4FMAPS</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">VNNI</span></th>
<th><span style="width:20px;writing-mode:vertical-rl;-webkit-transform:rotate(-180deg);-moz-transform:rotate(-180deg)">BF16</span>
</th></tr>
<tr>
<td rowspan="11"> Intel
</td>
<td> <a href="/wiki/intel/microarchitectures/knights_landing" title="intel/microarchitectures/knights landing">Knights Landing</a>   </td>
<td> 2016 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/knights_mill" title="intel/microarchitectures/knights mill">Knights Mill</a>      </td>
<td> 2017 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/skylake_(server)" title="intel/microarchitectures/skylake (server)">Skylake (server)</a>  </td>
<td> 2017 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/cannon_lake" title="intel/microarchitectures/cannon lake">Cannon Lake</a>       </td>
<td> 2018 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/cascade_lake" title="intel/microarchitectures/cascade lake">Cascade Lake</a>      </td>
<td> 2019 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/cooper_lake" title="intel/microarchitectures/cooper lake">Cooper Lake</a>       </td>
<td> 2020 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/tiger_lake" title="intel/microarchitectures/tiger lake">Tiger Lake</a>        </td>
<td> 2020 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="text-align: center; ;">  
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/rocket_lake" title="intel/microarchitectures/rocket lake">Rocket Lake</a>       </td>
<td> 2021 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="text-align: center; ;">  
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/alder_lake" title="intel/microarchitectures/alder lake">Alder Lake</a>        </td>
<td> 2021 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/ice_lake_(server)" title="intel/microarchitectures/ice lake (server)">Ice Lake (server)</a> </td>
<td> 2021 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘
</td></tr>
<tr>
<td> <a href="/wiki/intel/microarchitectures/sapphire_rapids" title="intel/microarchitectures/sapphire rapids">Sapphire Rapids</a>   </td>
<td> 2023 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="text-align: center; ;">  </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔
</td></tr>
<tr>
<td rowspan="1"> AMD
</td>
<td> <a href="/wiki/amd/microarchitectures/zen_4" title="amd/microarchitectures/zen 4">Zen 4</a>               </td>
<td> 2022 </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔
</td></tr>
<tr>
<td rowspan="1"> <a href="/wiki/Centaur_Technology" class="mw-redirect" title="Centaur Technology">Centaur</a>
</td>
<td> <a href="/wiki/centaur/microarchitectures/cha" title="centaur/microarchitectures/cha">CHA</a>            </td>
<td>      </td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #d6ffd8; text-align: center; ;"> ✔</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘</td>
<td style="background-color: #ffdad6; text-align: center; ;"> ✘
</td></tr></tbody></table>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=10" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ol class="references">
<li id="cite_note-Intel-248966-.2A-1"><span class="mw-cite-backlink">↑ <sup><a href="#cite_ref-Intel-248966-.2A_1-0">1.0</a></sup> <sup><a href="#cite_ref-Intel-248966-.2A_1-1">1.1</a></sup></span> <span class="reference-text"><a rel="nofollow" class="external text" href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">&#34;Intel® 64 and IA-32 Architectures Optimization Reference Manual&#34;</a>, Intel Order Nr. 248966, Rev. 046, January 2023</span>
</li>
</ol>
<h2><span class="mw-headline" id="Documents">Documents</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=x86/avx-512&amp;action=edit&amp;section=11" title="Edit section: Documents">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li> <a href="/wiki/File:Intel_Advanced_Vector_Extensions_2015-2016_Support_in_GNU_Compiler_Collection.pdf" title="File:Intel Advanced Vector Extensions 2015-2016 Support in GNU Compiler Collection.pdf">Intel® Advanced Vector Extensions 2015/2016</a>; GNU Tools Cauldron 2014; Presented by Kirill Yukhin of Intel, July 2014</li>
<li> <a rel="nofollow" class="external text" href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">&#34;Intel® 64 and IA-32 Architectures Software Developer’s Manual Volume 2 (2A, 2B, 2C &amp; 2D): Instruction Set Reference, A-Z&#34;</a>, Intel Order Nr. 325383, Rev. 078US, December 2022</li>
<li> <a rel="nofollow" class="external text" href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">&#34;Intel® Architecture Instruction Set Extensions and Future Features&#34;</a>, Intel Order Nr. 319433, Rev. 047, December 2022</li></ul>

<!-- Saved in parser cache with key wikichip:pcache:idhash:20932-0!*!0!!en!5!* and timestamp 20231205015359 and revision id 101239
 -->
</div><div class="visualClear"></div><div class="printfooter">Retrieved from &#34;<a dir="ltr" href="/w/index.php?title=x86/avx-512&amp;oldid=101239">/w/index.php?title=x86/avx-512&amp;oldid=101239</a>&#34;</div><div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Special:Categories" title="Special:Categories">Category</a>: <ul><li><a href="/wiki/Category:x86_extensions" title="Category:x86 extensions">x86 extensions</a></li></ul></div></div>				</div>
				
</div> <!-- mw-body-content END -->
</div> <!-- mw-body-content enclosure END -->
</div> <!-- wikichip-body-container END -->
<!-- wikichip-bottom START -->
<div id="wikichip-bottom">
    <!-- wikichip-footer-cont START -->
    <div id="wikichip-footer-cont">
    <!-- wikichip-afooter START -->
        <div id="wikichip-afooter">
                    	
			<!-- Ezoic - wikichip/global/footer - bottom_of_page -->
			<div id="ezoic-pub-ad-placeholder-127">
                	        <script async="" src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
                	        <ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-1951113009523412" data-ad-slot="3591436790" data-ad-format="auto"></ins>
                	        <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
			</div>
			<!-- End Ezoic - wikichip/global/footer - bottom_of_page -->

			                            </div>
    <!-- wikichip-afooter END -->
    <!-- wikichip-footer START -->
        <div id="wikichip-footer">

                                <div id="footer-last-mod">
                         This page was last modified on 16 March 2023, at 14:45.                        </div>
                                <div id="footer-places"><ul>
                        <li><a href="/wiki/WikiChip:Privacy_policy" title="WikiChip:Privacy policy">Privacy policy</a></li><li><a href="/wiki/WikiChip:About" title="WikiChip:About">About WikiChip</a></li><li><a href="/wiki/WikiChip:General_disclaimer" title="WikiChip:General disclaimer">Disclaimers</a></li>                        </ul></div>
                        
        </div>
    <!-- wikichip-footer END -->
    </div>
    <!-- wikichip-footer-cont END -->
</div>
<!-- wikichip-bottom START -->
 
    
    
<script>(window.RLQ=window.RLQ||[]).push(function(){mw.loader.load(["ext.smw.tooltips","ext.cite.a11y","mediawiki.toc","mediawiki.action.view.postEdit","site","mediawiki.user","mediawiki.hidpi","mediawiki.page.ready","mediawiki.searchSuggest","ext.headertabs","ext.headertabs.large","skins.WikiChip2.js"]);});</script><script>(window.RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":155});});</script></div>
<!-- A:IL01 START -->
<script type="text/javascript"> var infolinks_pid = 3234819; var infolinks_wsid = 0;</script>
<script type="text/javascript" src="//resources.infolinks.com/js/infolinks%5Fmain.js"></script>
<!-- A:IL01 END -->




<script>__ez.queue.addFile('/tardisrocinante/vitals.js', '/tardisrocinante/vitals.js?gcb=3&cb=3', false, ['/parsonsmaize/mulvane.js'], true, false, true, false);</script>
<script>var _audins_dom="wikichip_org",_audins_did=86609;__ez.queue.addDelayFunc("audins.js","__ez.script.add", "//go.ezodn.com/detroitchicago/audins.js?cb=195-3");</script><noscript><div style="display:none;"><img src="//pixel.quantserve.com/pixel/p-31iz6hfFutd16.gif?labels=Domain.wikichip_org,DomainId.86609" border="0" height="1" width="1" alt="Quantcast"/></div></noscript>
<script>__ez.queue.addFile('/beardeddragon/drake.js', '/beardeddragon/drake.js?gcb=3&cb=6', false, [], true, false, true, false);</script>
<script type="text/javascript" style='display:none;'>var __ez_dims = (function() {
		var setCookie = function( name, content, expiry ) {
			return document.cookie = name+'='+content+((expiry)?';expires='+(new Date(Math.floor(new Date().getTime()+expiry*1000)).toUTCString()):'')+';path=/';
		};
		var ffid = 1;
		var oh = window.screen.height;
		var ow = window.screen.width;
		var h = ffid === 1 ? oh : (oh > ow) ? oh : ow;
		var w = ffid === 1 ? ow : (oh > ow) ? ow : oh;
		var uh = window.innerHeight || document.documentElement.clientHeight || document.getElementsByTagName('body')[0].clientHeight;
		var uw = window.innerWidth || document.documentElement.clientWidth || document.getElementsByTagName('body')[0].clientWidth;
		setCookie('ezds', encodeURIComponent('ffid='+ffid+',w='+w+',h='+h), (31536e3*7));
		setCookie('ezohw', encodeURIComponent('w='+uw+',h='+uh), (31536e3*7));
	})();</script>
<script type='text/javascript' style='display:none;' async>__ez.queue.addFile('/parsonsmaize/chanute.js', '/parsonsmaize/chanute.js?a=a&cb=7&dcb=195-3&shcb=34', true, ['/parsonsmaize/mulvane.js'], true, false, false, false);</script>
<script type='text/javascript' style='display:none;' async>__ez.queue.addFile('/porpoiseant/jellyfish.js', '/porpoiseant/jellyfish.js?a=a&cb=11&dcb=195-3&shcb=34', false, [], true, false, false, false);</script></body></html>